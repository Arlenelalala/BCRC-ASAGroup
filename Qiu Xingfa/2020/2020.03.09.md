# 2020.03.09

* 对数据进行了重新分配，原来大约50个事件做训练集，450个事件做测试集，后来做了一些实验感觉训练数据不足，有点过拟合，就重新分配了数据，以2012-10-12至2012-10-22的数据为训练集，以2012-10-27至2012-11-06的数据为测试集，训练集和测试集的事件并无交集
* 主要根据论文 [Media Based on Neural Similarity Metric Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8004905) 尝试复现NSMED(A neural similarity metric based event detection method)方法，该方法主要是通过 bi-GRU+attention的方法，在判断两条推特是否属于同一事件的任务下，训练出一个推特的表示方法，再通过一种固定的事件表示公式，得到事件表示，最终测试时，通过计算推特-事件的相似度来判断推特所属事件。
* 在判断两条推特是否属于同一事件的任务中，从训练集随机抽取出19.6万对数据做训练，从测试集随机抽取11.8万对做测试，使用上述方法在训练集得到约0.95的准确率，测试集则约0.87的准确率
* 使用上述方法训练的模型进行聚类

| 方法          | NMI    | P      | R      | F1     |
| ------------- | ------ | ------ | ------ | ------ |
| UMASS(tf-idf) | 0.8116 | 0.6994 | 0.5427 | 0.6112 |
| avg_w2v       | 0.6591 | 0.1958 | 0.2154 | 0.2116 |
| NSMED         | 0.6952 | 0.3739 | 0.5485 | 0.4446 |

* 使用NSMED方法效果目前并没有无监督tf-idf方法的效果好，一方面可能训练数据还是不够充分，论文中使用了100万对数据训练，或者调参没有调到最优，另一方面可能模型本身效果可能不好，分类器在一对一的情况下可能表现较好，但在聚类阶段一对多的情况可能就会效果不理想

<br>

* 下一步计划
  * 对NSMED方法进行优化
  * 尝试ENJKE方法



<br>

<br>

<br>

<br>

<br>

<br>

---

## [Graph-based Event Extraction from Twitter](https://hal.inria.fr/hal-01561439/document)(RANLP 2017)

* 介绍

  * 使用时间序列的事件图，然后使用简单的图算法和类似Page-Rank的方法
  * 传统的基于关键词和命名实体的方法对于规模较小的事件不友好，而且拥有相同关键词而不属于同一事件的例子也很多
  * 文章将事件抽取分为 特定领域（有监督分类） 和 开放领域

* 方法

  * 推特预处理: 使用TweetMotifs对推特进行预处理，删除转发、url、表情和non-ASCII 字符，文章并没有去除停用词，因为停用词可能会是命名实体的一部分如of，然后使用规则将hashtag进行切分，使用SysSpell对拼错的词语进行纠正

  * 使用NERD-ML进行命名实体识别，并使用外部知识图谱进行链接
  * 将命名实体和其前后k个词语作为节点，如果出现在同一个命名实体窗口则建立边，以共现程度来表示权重
  * 使用图分割算法，并且使用类似PageRank的方法对节点排序



* 实验
  * 在FSD和EVENT2012上进行实验



---

## [Detection of Event Onset using Twitter](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7727381)(IJCNN 2016)

* 介绍

  * LDA方法需要提前定义事件，但对于noisy event不太能检测出来，LSH需要大量的计算

* 方法

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/001.png)

  * Tweet Tokenization and Graph Generation，删除特殊字符、停用词、URL和转发标识
  * Graph Pruning and Clustering，删除一些出现频率较低和不重要的词

* 实验

  * 使用event2012和Drug两个数据集

---

## [A Multi-view Clustering Model for Event Detection in Twitter](https://link.springer.com/content/pdf/10.1007%2F978-3-319-77116-8_27.pdf)(CICLing 2017)

* 介绍

  * 很少有方法考虑时间序列信息
  * 使用多视角聚类方法对关键词进行聚类
  * 基于文本聚类的方法需要处理大量的文本
  * 主题模型较难捕捉同一时间段的事件，对于短文本效果也不好
  * 关键词聚类是主要方法

* 方法

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/002.png)

  * 三个假设：1）关键词的集合可以代表事件；2）主题模型可以很好地捕捉到主题词；3）在同一时间段共同出现的词可能代表着同一事件
  * 使用DTW（dynamic time warping）算法计算两个词的距离

* 实验

  * 使用FSD2011和EVENT2012两个数据集
  * 使用ARK进行预处理
  * 与MABED和LDA方法进行对比
  * 使用人工评估



---

## [ A Novel Event Detection Model Basedon Graph Convolutional Network](https://kopernio.com/viewer?doi=10.1007/978-981-15-3281-8_15&route=6)(WISE 2019)

* 介绍

  * tf-idf和LDA的方法没有捕捉到文本的结构信息,本文提出使用图卷积网络的方法,使用ConceptGraph来表示文档,并使用SiameseGCN来计算相似度

* 方法

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/003.png)

  * 首先建立一个ConceptGraph,将结构信息和语义信息进行融合,然后训练一个SiamGCN,以初始化的conceptGraph作为输入,输出graph embedding,加上tf-idf向量和1维的时间向量,最后使用bik-means方法进行聚类
  * 使用jieba进行分词,使用LTP进行命名实体识别和关键词识别

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/004.png)

  * 首先构建关键词共现图,以一个句子作为时间窗口,将密集的子图称为concept,使用**betweenness centrality score** based on overlapping community detection algorithms 提取 concept,以平均word2vec来表示节点的初始特征向量,tf-idf相似度作为边权重
  * Siam GCN

  $$
  H^{(l+1)} = σ(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}H^{(l)}W^{(l)})
  $$

  * 通过L2 distance将两个graph embedding结合,并使用hing loss作为损失函数
  * 使用bik-means算法进行聚类

* 实验

  * 标注了中文数据集,包括12865对正样本和16198对负样本
  * 用一些方法作为baseline,TF-IDF,JS-IDF等方法,

