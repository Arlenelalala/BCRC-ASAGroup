# 2020.04.14

## [Multi-Perspective Relevance Matching with Hierarchical ConvNets for Social Media Search](https://aaai.org/ojs/index.php/AAAI/article/view/3790/3668)(AAAI 2019)

* 针对社交媒体文本的排序模型

* 在IR中，**relevance matching **是核心问题，与其他的NLP任务中的 **semantic matching** 区别开来（paraphrase detection & answer sentence selection）

* 在document ranking中queries 和 documents 是不平衡的，Siamese的结构并不适合

* 相对于传统的检索任务，社交媒体的搜索存在以下不同：

  * 文本长度
  * 非正式的文本（hashtag，缩写，拼写错误，emoji）
  * 多种的相关信息（url和hashtag）

* 贡献：

  * 考虑从词和字的角度建模，使得模型更加鲁棒
  * 使用分层的卷积网络捕捉不同层次的match signal
  * query和post（以及url）的匹配有一个相似度匹配层来实现

* 模型

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/005.png)

  * Multi-Perspective Input Modeling

    * 在社交媒体领域，OOV问题比较严重（混合词，非英文，拼写错误，缩写，专有名词等），作者发现50%-60%的词语为OOV，数据中约50的推特包含url
    * 在做相关匹配时考虑三个输入
      * query and post at word-level
      * query and post at character-level
      * query and URL at character-level（trigrams）

  * Hierarchical Representation Learning

    * 堆积了多层卷积网络（N=4），将最后一层的输出作为句子表示

    $$
    M^h = CNN^h(M^{h-1})
    $$

    * M0就是输入embedding，对于Q和D，CNN参数是共享的
    * 深层神经网络能够抽取更加高层和抽象的信息，并且可以捕捉长距离的依赖关系

  * Similarity Measurement andWeighting

    * 每层都对query和document进行了匹配，类似attention机制

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/006.png)

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/007.png)

    * 引入了IDF作为先验知识，降低了某些高频词的matching score

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/008.png)

    * 匹配的过程并没有需要学习的参数，使得模型更加鲁棒和可解释性更高，attention机制可以追踪到哪个输入对最终分数的贡献最高

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/009.png)

    * 使用对数损失

  * 实验

    * TREC Microblog Tracks 2011-2014，每个包含50个queries（三个做训练，一个做验证）

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/010.png)

    * 不同于其他方法直接将query和document相乘得到相似度，本文通过多层CNN得到更好的语义表示，并且通过字级别的信息对relevance signals进行了补充

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/011.png)

    

    

* 总结

  * 第一个在社交媒体文本上使用neural ranking models进行检索的工作
  * 从输入query，document和url的词和字的角度考虑相关性
  * 通过多层CNN进行特征抽取
  * 通过idf引入attention

* 思考

  * CNN模块和腾讯在17年提出的DPCNN类似，DPCNN结构更深，7个模块，每个模块两层卷积，还有残差结构
  * 使用idf进行attention比较特别

  

  

---

## [Adversarial Training for Community Question Answer Selection Based on Multi-Scale Matching](https://aaai.org/ojs/index.php/AAAI/article/view/3810/3688)(AAAI 2019)

* Community-based question answering，选择式，有两种模式，一种是根据新问题选择相似问题，另一种是根据问题选择答案，

* 作者将这看做二分类问题，用二分类问题的思路来解决匹配问题，存在样本不平衡的问题，绝大多数QA是不匹配的，如SemEval 2017中只有2.8%是匹配的，作者选择了使用了对抗训练的方法减轻样本不平衡的问题，使用生成式模型G选择负样本去挑战分类器，随机选择的负样本对模型的贡献很小

* 同时考虑word和n-gram不同粒度

* Adversarial Training

  * generator学习到真实分布P_data(A|Q)，然后generate (**sample**) relevant answers，另一方面，discriminator用来判断相关或不相关

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/012.png)

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/013.png)

  * 建立另一个同样的Multi-scale Matching model，然后得到 **所有** 候选答案（实际实验时只挑选了固定数量，包括已标注的负例和其他问题的答案）的分数，给置信度高的答案更高的被挑选概率（top10）
  * GAN要求generator 和 discriminator都是可微的，随机采样的方法并非可微的，使用policy gradient(强化学习)方法解决这个问题，PG作为action，而log(1-D(A'|D))作为reword（**？**）

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/014.png)

* Multi-scale Matching Model

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/015.png)

  * 用了k个CNN模块对输入进行编码，得到k层表示

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/016.png)

* 实验

  * SemEval 2017

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/017.png)

  * SemEval 2016

    ![](C:/Users/qxf/Documents/opinion/TDT/pic/018.png)

    * 效果不如其他，因为数据更均衡一些，对抗训练的动机就是采样更少的负样本

* 总结

  * 用二分类的思路来进行QA，并且使用了对抗训练的策略减缓样本不均衡的问题，generative model用来挑选更有挑战性的负样本，使用Multi-scale Matching
    model获取不同粒度的匹配信息