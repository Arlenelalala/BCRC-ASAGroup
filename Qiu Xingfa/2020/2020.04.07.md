# 2020.04.07



* 实验

  ![](https://upload-images.jianshu.io/upload_images/2528310-f1c3bce8c895ba1d..jpg?imageMogr2/auto-orient/strip|imageView2/2/w/600/format/webp)

  ![](https://upload-images.jianshu.io/upload_images/2528310-bdf35c69fea7b6ff..jpg?imageMogr2/auto-orient/strip|imageView2/2/w/600/format/webp)

  * 整个网络最重要的就是两个部分  input 和 network
  * 对于一般的短文本匹配任务来说，一般使用孪生网络的结构，即共享参数的方法
  * 对于NSMED方法来说，input就是推特文本，network就是bi-GRU+attention，输出推特的一维表示
  * 对于文本-事件的匹配来说，左右输入并不对称，所以应使用不共享参数的伪孪生网络
  * 对于事件输入，考虑以词为核心的表示方法
  * 尝试不同的结构作为Network，包括GRU，LSTM和Transformer

  |                         | NMI        | ARI        | P          | R          | F1         |
  | ----------------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
  | tf-idf                  | 0.7825     | 0.3047     | **0.6998** | 0.2015     | 0.3129     |
  | NSMED(bi-GRU+attn,共享) | 0.7866     | 0.5334     | 0.5141     | 0.5831     | 0.5464     |
  | bi-GRU+attn             | **0.8132** | **0.6961** | 0.6725     | **0.7396** | **0.7044** |
  | bi-LSTM+attn            | 0.7459     | 0.6822     | 0.6489     | 0.7391     | 0.6911     |
  | Transformer             | 0.6562     | 0.6282     | 0.5965     | 0.6871     | 0.6386     |

  * 分开输入文本和事件明显得到了较好的结果，Tansformer参数较多，容易过拟合，较难训练，在测试集并未得到较好的结果

* 以上实验基本说明用某些词来作为输入表示事件是可行的且可解释的

* 对于事件来说，图是比较合适的表示方法

* 接下来重点在于把图表示模型搭起来





* 专利
* 实习