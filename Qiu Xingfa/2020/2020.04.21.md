# 2020.04.21

## [Matching Article Pairs with Graphical Decomposition and Convolutions](https://www.aclweb.org/anthology/P19-1632.pdf)（ACL 2019）

* 任务：文章匹配（判断文章是否描述同一新闻）

* 现有方法大部分为句子级别的匹配所设计，在长文本匹配中效果不好，作者使用Concept Interaction Graph表示文章

* Concept Interaction Graph

  * concept 为相似句子中的关键词（TextRank）集合（聚类），将每个句子分配到最近的concept节点，边表示concept之间的关联程度

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/019.png)

  * KeyGraph Construction：使用TextRank的方法提取关键词，连接同时出现在一个句子中的关键词
  * Concept Detection：使用Community detection将图进行划分，使用betweenness centrality score based algorithm，减少了节点数，加速了匹配过程
  * Sentence Attachment：用tf-idf相似度，将句子分配到最近的节点
  * Edge Construction：用tf-idf相似度
  * Encoding Local Matching Vectors：包括孪生网络的输出和tf-idf相似度等
  * Matching Aggregation via GCN：将上面的Matching Vectors拼接起来作为输出，邻接矩阵定义为节点之间的tf-idf相似度

  $$
  H^{(l+1)} = \sigma(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}H^{(l)}W^{l})
  $$

  * 将最后一层的输出取平均后输入全连接层得到最终结果

* 实验

  * 使用标注的新闻数据，正负例大致均衡，负例挑选包含相似关键词但不属于同一事件的新闻对
  * 使用一些传统的匹配方法作为baseline，包括LDA，DSSM，C-DSSM，ARC-I，ARC-II以及BERT等等

  ![](C:/Users/qxf/Documents/opinion/TDT/pic/020.png)

  * community detection 带来了更差的效果，直接用关键词作为节点可以得到更好的效果，但是community detection能将平均节点数从30降到13，可节约55%的计算时间
  * 在最后增加Global Features对结果影响很小，表示主要是GCN在起作用

* 总结

  * 主要是构建了Concept Interaction Graph，然后使用GCN的方法进行匹配
  * 疑问：如果两篇文章不是同一事件，如何构建Concept Interaction Graph？如何保证每个节点都有来自doc1和doc2的句子？



---

## 实验

* 尝试用GCN和GAT对事件进行编码

  * 关键在于图的定义
  * 挑了固定长度的关键词作为节点
  * 权重使用PMI(Pointwise Mutual Information)

  $$
  PMI(i,j) = log(\frac{p(\omega_1,\omega_2)}{p(\omega_1)*p(\omega_2)})
  $$

* GCN

  ![](https://www.zhihu.com/equation?tex=H%5E%7B%28l%2B1%29%7D%3D%5Csigma%28%5Ctilde%7BD%7D%5E%7B-1%2F2%7D%5Ctilde%7BA%7D%5Ctilde%7BD%7D%5E%7B-1%2F2%7DH%5E%7B%28t%29%7DW%5E%7B%28l%29%7D%29)

* GAT

![](https://pics4.baidu.com/feed/b8389b504fc2d5624617f8f6a711f6eb76c66c96.jpeg?token=581b6d6431a0564640d7ab708a7b9614&s=449265324D12D5CC46C0C0DE02004032)



* 结果

  * 在匹配数据集中

  | 特征提取器          | acc    |
  | ------------------- | ------ |
  | Bi-GRU              | 0.9542 |
  | Bi-LSTM             | 0.9330 |
  | Transformer-encoder | 0.8469 |
  | GCN                 | 0.7423 |
  | GAT                 | 0.9227 |

  * 聚类评估

  |                         | NMI        | ARI        | P          | R          | F1         |
| ----------------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
  | tf-idf                  | 0.7825     | 0.3047     | **0.6998** | 0.2015     | 0.3129     |
  | NSMED                   | 0.7928     | 0.2618     | 0.6042     | 0.1742     | 0.2704     |
  | NSMED(bi-GRU+attn,共享) | 0.7866     | 0.5334     | 0.5141     | 0.5831     | 0.5464     |
  | bi-GRU+attn             | **0.8132** | **0.6961** | 0.6725     | **0.7396** | **0.7044** |
  | bi-LSTM+attn            | 0.7459     | 0.6822     | 0.6489     | 0.7391     | 0.6911     |
  | Transformer-encoder     | 0.6562     | 0.6282     | 0.5965     | 0.6871     | 0.6386     |
  | GCN                     | \          | \          | \          | \          | \          |
  | GAT                     | 0.6597     | 0.3632     | 0.4054     | 0.3555     | 0.3788     |
  
  * 分析
    * 目前来说还是bi-GRU作为事件特征提取器的效果最好
    * 训练方法和聚类策略对最终结果的影响很大，事件分布极不均衡，一个事件最多3406个文本，最少1个，平均133
    * GAT可能存在过拟合的情况，泛化性不如GRU
    * 匹配数据集还不够具有代表性
  
  
  
  * 计划
    * 进一步分析实验结果，对模型进行优化
    * 扩充匹配数据
    * pointwise --> pairwise + hingeloss

