# 2019.3.7_知识图谱

* 主要看了DKN和TransE两篇论文和《知识图谱》几章内容
* 下周计划对知识图谱嵌入和事件抽取进行调研
* 知识图谱，事件库基本框架的建立以及分析方法依然需要研究，需要清楚我们有什么，要什么，怎么用


---
## [DKN: Deep Knowledge-Aware Network for News Recommendation](https://arxiv.org/pdf/1801.08284v1.pdf)

* 新闻推荐具有高度的时间敏感性和用户兴趣的动态变化性，
* KCNN使用了多通道方法，把word embedding, entity embedding 和 contextual entityembedding of news作为类似图片的多个通道， 
* BOW方法忽略了词序，而且存在稀疏性问题

* 论文中的方法只是将标题的实体识别出来作为embedding输入，是否可以结合文章内容，但是用户看到的只有文章标题，是否只是文章标题决定用户是否点击，怎么优化知识图谱embedding，

---
## [Translating Embeddings for Modeling Multi-relational Data](https://www.utc.fr/~bordesan/dokuwiki/_media/en/transe_nips13.pdf)

![](https://github.com/qiuxingfa/picture_/blob/master/2019/e28231c59130a3e2f27094c0bacf12c.png)<br>

* 虽然TransE模型简单有效，但是它并不能处理1-N，N-1,N-N的问题。比如，一个导演指导了多部电影，根据头节点h（导演），关系r（指导），尾节点t（电影）进行模型训练，那么这些电影向量的距离是很近的，而事实上他们是完全不同的实体。 
* TransH 依然把实体 h,t 表示为向量，但是把关系r表示成两个向量：超平面的法向量 Wr和关系r在超平面内的向量表示 dr。
* TransR —— 在TransE和TransH这两个模型中，实体和关系向量被映射到同一个向量空间。TansR把关系向量映射到不同的空间。与TransH相比，TransR把关系r映射到与它相关的空间而不是超平面。
* TransD —— TransD可以说是TransR/CTransR的简化版本，它用两个向量来动态重构mapping矩阵。TransD中没有很复杂的矩阵运算，取而代之的是向量运算，因而比TransR的复杂度要低。

---
## 序
* 知识图谱标准化的表示方式，使得知识图谱能够包含足够多足够全的知识，且这种表示对于计算机是友好的，但是目前的知识表示还只是浮于表面，只是对于最浅层知识的提取（尽管这也很不容易），很多深层次的知识，隐藏的知识，怎么在不同场景下对知识进行运用，都是自然语言理解结合知识图谱亟待解决的问题。
* 知识图谱可作为自然语言理解的“背景知识库”，类似于人类的“联想”能力，在对文字进行理解处理时，不再限于对当前文章的理解，而是通过知识图谱，识别出一些关键节点，通过这些关键节点在知识图谱中的位置，辅助对于自然语言的理解，尝试从知识图谱中了解一些隐藏的知识，提取更高层次的知识。
* 知识图谱的构造需要自然语言理解的帮助，而构造知识图谱也是为了机器更好地理解自然语言，运用自然语言，两者关系是相辅相成的。

## 第一章 概述
> * 数据的结构化并和已有的结构化数据进行关联，就构成**知识图谱**。
* **本体**是通过对象类型、属性类型以及关系类型对领域知识进行形式化描述的模型。本体强调的是抽象的概念表示，例如不同类型的人、他们之间具有什么类型的语义关系，而不关注于具体的个体信息，例如某人是什么类型的人，某人和某人是什么关系。
* 框架（Schema，或称“元知识”）就是对知识的描述和定义，知识框架和实例数据共同构成一个完整的知识系统。
* **资源描述框架**（RDF)的基本数据模型包括了三个对象类型：资源（resource）、谓词（predicate）及陈述（statement）
* 由于数据的稀疏性，我们很难利用抽取或者融合的方法对于缺失的知识进行补齐。因此，需要采用推理的手段发现已有知识中隐含的知识。

* 就像计算机试图用0和1表示数字世界，知识图谱试图用结构化三元组（头实体，尾实体，关系（属性））的形式来表示知识。
* 构造三元组步骤：确定需要识别的实体，实体的类型，进行实体识别，实体消歧，确定实体间的关系类型，关系抽取。对于事件抽取，首先要抽取出事件实体，再来就是事件属性，还有就是和其他事件的关系。

## 第二章 知识表示
> * **逻辑表示**能够保证知识表示的一致性，也能够确保推理结果的正确性。但是，这种产生式表示方法难以表示过程性知识和不确定性知识，而且当表示知识中的属性、谓词和命题数量增大时，其推理过程因为符号的组合爆炸问题，计算复杂性呈指数型增长态势。因此，基于谓词逻辑的推理过程比较耗时，工作效率较低。
* **语义网络**用一种最简单的一种统一形式描述所有知识，非常有利于计算机的存储和检索。语义网络的缺点是，它仅用节点及其关系描述知识，推理过程不像谓词逻辑表示方法那样明了，需要针对不同关系做不同处理，推理方法还不完善。
* **网络本体语言**（Web Ontology Language，OWL）.

* 各类表示方法的不同在于人工定义的规则的多少，规则越少，自由度越大，对计算机越友好，反之，规则越多，越有利于推理，但是对于数据的处理和知识的提取越不利

## 第三章 知识体系构建和知识融合

> * **知识体系**主要包括三个方面的内容：对概念的分类、概念属性的描述以及概念之间的相互关系的定义。知识体系的基本形态包括词汇、概念、分类关系、非分类关系和公理这五个不同层次。
* 真正进行构建之前，应该广泛调研现有的第三方知识体系或与之相关的资源，尽可能多地参考前人的已有成果。
* **基于非结构化文本的知识体系学习**方法包括以下三个主要步骤：领域概念抽取、分类体系构建、属性概念及关系抽取。
* **模型联合学习**，首先利用简单的对齐方法，例如字符串匹配，来产生初始的种子对齐，然后采用TransE的方式，，学习两个知识库的对齐。

* 如何利用已有开放资源，如何定义知识体系的基本框架，都是在构建知识图谱之前需要思考清楚的问题，目前我们不需要大而全的知识图谱，所以必须有所侧重，有所取舍。人工的方法较为繁琐，工作量大，数据质量高，统计方法速度快但效果较差，目前还无法脱离人工实现完全自动化。    
* 模型联合学习可用于利用现有开放知识库来链接我们所需要构建的知识库。

## 第四章 实体识别和扩展

> * **基于规则**的命名实体识别方法在特定领域的小规模语料上测试效果较好，速度快。
* **细粒度**实体识别的难点在于：类别的制定（最直接的方法是人工制定，此外最具代表性的工作是利用人工构建的词典知识资源作为类别的来源，语料的标注，实体识别的方法
* 华盛顿大学的**KnowItAll系统**是一个比较有代表性的**无监督**的细粒度实体抽取系统，主要由三部分组成：规则抽取，实体名的抽取和实体名的验证。
* **实体扩展**系统主要由三个模块组成：种子处理模块，实体抽取模块，结果过滤模块

* **种子**究竟应该如何获取、生成和使用？如何做到抽取而不是识别？

## 第五章 实体消歧
> * 目前还缺少对链接候选过滤方法的系统化研究和量化分析，大部分工作都是基于实体指称项词典：通过在词典中记录一个指称项所有可能指向的目标实体来进行链接
* 在**主题一致性模型**中，决定一致性打分的是实体指称项的候选实体概念与指称项上下文中的其他实体概念的一致性程度。在计算一致性打分时，通常需要考虑如下两个因素：（1）上下文实体的重要程度（2）如何计算一致性

## 第六章 关系抽取
> * 限定域关系抽取类似于文本分类任务，很多研究利用弱监督薛学习的方法抽取关系
* 基于模板的关系抽取方法的最大问题在于其受限于模板的质量和覆盖度
* 距离监督利用知识图谱自动标注训练样本
* 开放域关系抽取语料的自动生成主要是通过依存句法分析结合启发式规则自动生成语料。开放域关系抽取得到的关系无法直接映射到知识图谱中。限定域的关系抽取是目前研究的主流方向。

* 舆情不是要做一个百科型的知识图谱，所以我们不需要识别出所有实体，所有关系，那么什么才是我们想要的呢？ 事件

-----








