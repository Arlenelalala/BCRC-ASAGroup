# 2019.11.7

---
* 在微博标注数据集上使用了很多无监督的方法进行测试，发现用tf-idf相似度和字符相似度的效果会略好于词向量相似度，可能的原因是：1）数据标注时用标签的直接匹配，从字符角度的相似度相对有优势；2）词向量相似度所带来的噪音更大，对于聚类效果有较大的负面影响
* 在聚类完全正确的假设下直接匹配可能没有意义，模型对于噪音和漂移没有很好的处理能力，前后输入数据并不是严格的pipeline的关系，错误传播可能没有那么严重，但也是一个很重要的问题，
* 把每一步的状态都保存下来，作为标准，和当前时刻的状态进行比较，用NMI（Normalized Mutual Information）作为损失函数
* 用文本相似度甚至语义相似度来作为判断是否同一事件并不完全准确，事件的要素其实会比文本的相似更加重要，两篇微博在讨论同一件事情时可能从文本的角度是完全不一样的

* 下一步计划分析无监督结果，进行有监督实验



|方法|P|R|F1|purity|entropy|NMI|
|---|
|1 直接匹配|0.2242|0.2375|0.2374|0.7942|0.9158|0.7987|
|2|0.8605|0.1625|0.2734|0.9264|0.2687|0.8388|
|3 Jaccard相似|**0.9655**|0.0746|0.1386|**0.9646**|**0.1331**|0.8019|
|4|0.9288|0.1030|0.1855|0.9382|0.2282|0.8170|
|5|0.9251|0.1369|0.2385|0.9594|0.1725|0.8396|
|6 字符相似度|0.9050|0.4000|0.5547|0.9299|0.2945|0.8935|
|7|0.8201|0.5266|0.6414|0.8498|0.8871|0.5833|
|8|0.8511|0.3960|0.5405|0.9149|0.3746|0.8857|
|9|0.8810|0.4459|0.5921|0.8993|0.4008|0.8915|
|10|0.7524|**0.5874**|0.6597|0.7878|0.8234|0.8707|
|11|0.7932|0.4584|0.5810|0.8690|0.5289|0.8825|
|12 tf-idf|0.9012|0.5244|0.6630|0.9311|0.2989|**0.8969**|
|13|0.8383|0.5557|**0.6683**|0.8835|0.4505|0.8919|
|14|0.8846|0.4308|0.5794|0.9301|0.3022|0.8912|
|15 w2v|0.8431|0.4320|0.5712|0.9257|0.3116|0.8761|
|16|0.6748|0.5166|0.5852|0.8361|0.6611|0.8595|
|17|0.8461|0.4304|0.5706|0.9283|0.3039|0.8755|

方法1：当前微博以最长标签为代表，匹配事件所有标签
方法2：当前微博以最长标签为代表，匹配事件内出现频率前五的标签
方法3：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算Jaccard相似度，0.3为阈值
方法4：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算Jaccard相似度，0.2为阈值
方法5：当前微博以最长标签为代表，事件以所有超过阈值0.4的标签拼接为代表，计算Jaccard相似度，0.3为阈值
方法6：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算字符相似度，0.3为阈值
方法7：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算字符相似度，0.2为阈值
方法8：当前微博以最长标签为代表，事件以所有超过阈值0.4的标签拼接为代表，计算字符相似度，0.3为阈值
方法9：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算字符相似度，0.3为阈值
方法10：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算字符相似度，0.2为阈值
方法11：当前微博以最长标签为代表，事件以超过阈值0.4的所有微博的最长标签拼接为代表，计算字符相似度，0.3为阈值
方法12：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算tf-idf相似度，0.3为阈值
方法13：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算tf-idf相似度，0.2为阈值
方法14：当前微博以最长标签为代表，事件以超过阈值0.4的所有微博的最长标签拼接为代表，计算tf-idf相似度，0.3为阈值
方法15：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算w2c相似度，0.75为阈值
方法16：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算w2v相似度，0.7为阈值
方法17：当前微博以最长标签为代表，事件以超过阈值0.8的所有微博的最长标签拼接为代表，计算w2v相似度，0.75为阈值
<br>
<br>
<br>
<br>
<br>

---
## [Semi-supervised Question Retrieval with Gated Convolutions](https://arxiv.org/pdf/1512.05726.pdf)

### Abstract
* The task is difficult since 1) key pieces of information are often buried in extraneous details in the question body and 2) available annotations on similar questions are scarce and fragmented.
* Several factors make the problem difficult. 
    * First, submitted questions are often long and contain extraneous information irrelevant to the main question being asked.
    * The second challenge arises from the noisy annotations.

### 思考
* 作者在问句匹配任务中使用一正一负的句子对作为训练数据

---
## [Feature Driven Learning Framework for Cybersecurity Event Detection](https://asonamdata.com/ASONAM2019_Proceedings/pdf/papers/029_0196_083.pdf)
* 对于社交媒体的网络安全事件检测，之前的方法基本上是集中于无监督和弱监督的方法，这些方法在现实中效果不佳，存在特征稀疏、处理弱信号（在大量数据中的少量数据）能力不强，模型泛化能力不强等缺点，这篇论文提出了一种多任务学习的有监督模型
* 将不同种类的目标机构视为不同的任务
* 收集2014年1月至2016年12月的893个网络安全事件，将大量的推特数据分为训练集和测试集，用命名实体所属机构进行标注

* 标注方法存疑

---
## [Jointly Detecting and Extracting Social Events From Twitter Using Gated BiLSTM-CRF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8866717&tag=1)
### 简介
* 使用pipeline的方法会造成错误传播，许多方法经常基于手工特征和现成的NLP工具（不适用于短文本）
* 提出在用深度学习的方法在推特中联合检测和提取事件的方法，将事件发现任务认为是二分类任务，而元素提取任务当成序列标注问题，进行联合学习，使用BiLSTM-CRF的结构

### 相关工作
* 社交媒体的事件发现：可分为开放领域和特定领域，开放领域经常使用无监督聚类的方法，而特定领域经常使用有监督分类的方法，依赖于特征工程和现有的NLP工具
* 社交媒体的事件提取：用pipeline的方法进行事件的发现和提取
* 联合模型：Zhang联合发现、聚类和摘要

### 问题定义
* 判断一条给定的推特是否和感兴趣的事件(二分类)，相关然后提取推特中的事件元素
* 事件定义为在特定的时间和地点发生的包含一个及以上参与者的事情，由四元组（触发词，时间，地点，参与者）组成，其中触发词是必须的

### 方法
* 将事件检测定义为二分类问题，判断是否与社会事件相关
* ![](https://github.com/qiuxingfa/picture_/blob/master/2019/3830b4b6feddd7cd6d116d7945793dc.png)

### 实验
* 选择“社会动乱”事件做二分类，
* 在五个月的中文推特里根据某些关键词选出33094条推特，通过SimHash删除重复推特，去除明显与事件无关的推特，最后人工标注，剩余3000正例和3000负例
* 使用5w条新闻和收集的推特进行词向量训练

### 思考
* 依然是pipeline，共享了一部分参数
* 标注的方式很大程度上决定了解决的问题，文中根据关键词的方法进行事件检测，解决的就是针对特定领域事件的推特进行判断，正负均衡，泛化性不高

---




