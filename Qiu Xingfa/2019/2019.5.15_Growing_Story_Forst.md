# 2019.5.15_Growing_Story_Forst
---
* 参考论文 [Growing Story Forst Online from Massive Breaking News](https://arxiv.org/pdf/1803.00189.pdf)
* 修改事件库结构，增加故事节点，故事-->事件-->文章-->关键词，故事和时间会进行动态更新，增加时间特性（但时间特征和相似度不一定是正比关系），事件和文章，事件和事件，事件和故事之间均可直接计算相似度，线性加权式的相似度计算过于简单，有待改进。
<br>
* 接下来，找一些Text Clustering; Online Story Tree; Information Retrieva相关论文
* 社区发现算法调研
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

---
## [Growing Story Forst Online from Massive Breaking News](https://arxiv.org/pdf/1803.00189.pdf)

* ABSTRACT
    * 从大量的即时新闻中抽取事件，并以在线的模式更新新闻故事的结构
    * 与之前的话题检测和追踪，事件时间轴，图谱生成不同，1）我们需要快速地精准地从大量包含多种话题和冗余信息的长文本中提取出可区分的事件；2）而且在不需要反复地重构之前的故事的情况下，需在线地更新故事结构
    * Story Forest：在线地将流动文档聚类为事件的策略
    * KEYWORDS：Text Clustering; Online Story Tree; Information Retrieval
* INTRODUCTION
    * 有通过事件时间线、事件线程、事件演化图或者信息图来抽取事件的
    * 但依然没有得到大规模部署的原因：
        * 以一个合适的粒度从大量的新闻中抽取出可区分的事件依然充满挑战，新闻报道可能包含不同的主题和大量的冗余信息，即使有了关键词图谱，用户依然需要付出额外的努力去理解每个关键词集合里的文章
        * 有许多方法尝试将事件图与任意的其他事件图进行链接，**过于复杂**的图结构并不利于用户理解新闻数据，实际上，与搜索引擎需要复杂的故事不同，大部分即时新闻遵循少量的典型的发展结构，简单的事件结构更为重要。
        * 更为重要的是，大部分现有的事件抽取方法都是基于整个新闻数据的线下的进行优化，并没有对之前的事件进行调整和重组，在线的方法可以将一个事件连续地展示给用户，减少延时
    * 论文贡献
        * 通过两层的文档聚类，我们的系统可以对大量的新闻文本进行准确的聚类，使用了大量特征工程和机器学习技术，主要包括关键词提取，关键词社区发现，预训练的分类器分类两篇文章是否为同一事件，以及基于图的文本聚类
        * 将事件进一步分类为故事，每个故事由事件树构成，两个事件之间的关系代表时间迁移或因果关系，与现有的一些系统不同，我们使用了一种在线算法递增地对事件树进行更新
        * 在60GB新闻数据的结果与其他baseline比效果最好，完成事件聚类和故事结构的平均时间为30s
* PROBLEM DEFINITION AND NOTATIONS
    * topic --> story --> event
    * 事件是最小单元
    * 树结构
* THE STORY FOREST SYSTEM
    * 三个部分：预处理，文本聚类，故事树更新
    * 五个步骤：第一，使用NLP和机器学习工具处理数据，主要包括文档过滤，分词，关键词提取；然后，通过两层过程将文档聚类为事件，首先在文本的关键词以及话题图种用**社区发现**算法，然后进一步地用一个预训练的pdocument-pair relationship classi€er通过半监督方法将文档聚类为事件；最后，更新事件树。
    * 预处理：
        * 文档过滤：小于20字的文档将被过滤
        * 用Stanford Chinese Word Segmenter 进行分词
        * 关键词提取：TF-IDF和TextRank在真实数据中效果不好，TF-IDF提取出的词难以提取出低频关键词，TextRank使用了词共现信息，可以解决这个问题，但效率很低，当文档长度增加时，时间消耗显著增加。
        * 使用了一种有监督的学习系统判断一个词是否是一个文档的关键词，标注了10000+条数据，包括20000+正例和350000+负例，提取了以下特征,结合了梯度增强决策树和逻辑回归<br>
        ![](https://github.com/qiuxingfa/picture_/blob/master/2019/c18f27228014831f826cec756d64549.png)<br>
    * 文本聚类和事件抽取：事件抽取本质上是对文本聚类结果进行fine-tune，用了两层的聚类方法
        * 首先，构建了一个巨大的关键词共现图，边表示两个关键词同时出现过
        * 然后，在关键词共现图中使用社区发现算法，每个社区包含一个确定的话题，每个关键词可以出现在不同的社区，用word2vec的方法聚类关键词比社区发现算法的效果要差（word2vec方法会将语义相近的关键词聚类到一起），使用betweenness centrality score of edges衡量边的权重值，定义为节点对经过这条边最短路径的数量，两个社区之间的边的betweenness score会趋向于更高，分数高的边将被去掉来进行社区发现，然后计算文档（用TF-IDF向量表示）和关键词社区（同样看成一个文档）的余弦相似度，将文档归入相似度最高的社区，至此，文档根据话题进行了第一层聚类
        * 第三步，在每个话题内进行文档聚类，得到事件，使用了有监督的聚类，训练了一个SVM分类器判断两个文档是否属于同一事件，`一个事件不会出现在多个话题里`，在文档图中使用社区发现算法
    * 在线生成故事树：
        * 判断事件属于那个故事树（计算事件和故事树关键词的Jaccard相似度）`慢`
        * 更新故事树，将事件归入或者新建故事（考虑时间距离`用了一个指数函数，时间差距为负值则为0，但其实我们无法保证新闻数据是按时间排序的，且认为时间越长相似度越低，这不准确`，兼容性，和故事线中每个节点的兼容性）
* EVALUATION
    * 3个月60G的新闻数据，用7天的数据进行参数训练，剩下的用来测试
    * 事件聚类评估
        * 3500条标注数据
        * 同质性和完整性
    * 故事结构
        * 人工判断，261个故事
        * 大多数真实新闻数据并没有复杂的结构
    * 算法复杂度
        * 40分钟
        * 平均一天的数据处理时间26秒
        * 关键词提取，每秒50个文档
     
---
## [人机交互场景下的知识挖掘](https://www.bilibili.com/video/av51991812)

* 对话日志挖掘
    * 预处理
    * 过滤问题（二分类）
        * 规则识别（不合规字符，长度过长，不文明用语）（完备性/一致性难协调）
        * 语句通顺度（胡言乱语）
    * 派发问题（知识库派工预测）
        * 难点：语料分类交叠+短文本（稀疏）
        * 分词+去停用词，同近义词转换，聚类，多分类模型（TEXTCNN，简单轻快，TMN，NTM神经主题模型）
    * 提升标注效率（业务定制，自动填充，Query聚类，相似标准问）
    * 主动挖掘知识（基于阅读理解的问答对挖掘）
    * 知识构建与KBQA
        * 结构化保险条款+知识融合 --> 保险知识
        * KBQA：语义解析，答案排序
        * 实体消歧，命名实体识别，主题实体识别-->关系抽取，属性判断-->策略判断，实体模板生成器
* 事件挖掘：资讯热点事件挖掘的关键步骤
    * 爬虫
    * 事件生成（关键字，主题，同主题下文章划分事件，社区发现）（层次聚类，减轻计算量）
    * 事件追踪（分类模型，规则，相似度，SVM，GCN）（连续性，故事脉络，**Growing Story Forst Online from Massive Breaking News**）（树结构）
    * 内容模型（命名实体识别，摘要生成，事件要素识别，情感，主题，热点指数）
    * 应用（语义检索，营销素材，资讯流推荐，舆情监控）       
 
---
## [Linking Temporal Records](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=1BCD8D42DED45CAFC06B4FA962CD9B7A?doi=10.1.1.227.8996&rep=rep1&type=pdf)

* ABSTRACT
    * 为了能够识别在不同时间描述同一实体的记录
    * 应用时间衰减模型
* INTRODUCTION
    * 实体链接

---

## 第6章 新型的实体识别技术
> * 基于时间模型的实体识别技术
>    * 时间衰减模型
>       * 不一致衰减模型：在△t时间内实体属性A取值发生改变的概率
>       * 一致衰减模型
>    * 实体突变模型
>   * **early binding**算法
>       * 计算记录r与每个已存在聚类的相似度
>       * 选择与记录r有最大相似度的聚类，如果超过阈值，则合并，否则单独成立一个聚类
>       * 更新r所在聚类的聚类签名（属性，最小和最大时间戳）
>   * **late binding** 算法
>       * 与early binding算法不同，late binding算法并不急于将记录与已有的聚类合并，而是保留所有的记录与聚类的相似度，最后依据全局确定记录所属聚类。late binding算法维持一个双向图（N_R,N_C,E),N_R表示记录的集合，N_C表示聚类的集合，E表示记录与聚类的边的集合，并标明记录与聚类之间的相似度
>       * 证据收集阶段，计算每一条记录与已有聚类的相似度，规范化边权值，边权值为一条记录属于一个聚类的概率
>       * 决策阶段，选择保留最高权重的边
>   * **adjusted binding**算法
>       * 允许一条记录与**后产生的聚类**进行相似度计算
>       * 初始化，通过early binding和late binding算法得到一个初始的划分
>       * E-step，计算每一条记录与聚类的的相似度，并如late binding一样对这些相似度进行标准化
>       * M-step,为每一条记录选择具有最大概率权重的聚类
>       * 终止条件，重复EM步骤直到聚类结果不再变化
>   * **SFDS**算法
>       * 在SFDS算法中，将实体演化的情况转化为捕捉实体从一个聚类是否会演化为另一个聚类的情况
>       * 静态阶段
>       * 动态阶段：基于时间衰减模型计算每一个聚类Ci与已存在的聚类Di的动态相似度
>   * **AFDS**算法
>   * 基于条件概率模型的实体识别算法
>   * 基于属性值转换模型的实体识别算法


* late binding不适合动态的不确定的数据，事件聚类必须是动态的，adjusted binding算法计算每一条记录与当前聚类的相似度计算量太大

## 第7章 实体识别评估
* 基于记录对的精确评价——P、R、F
* 分块技术评价
    * n_M:匹配的记录对集合，n_N:不匹配的记录对集合，s_M:分块之后匹配的记录对集合，s_N:分块之后不匹配的记录对集合
    * 减少率（Reduction Ratio）：用来衡量比较空间的减少率，1-(s_M+s_N)/(n_M+n_N)
    * 记录对完整性（Pairs Completeness）：通过分块技术生成的匹配的候选记录对的数目与真实的匹配的记录对的数目的比值，s_M/n_M
    * 记录对质量（Pairs Quality）：通过分块技术生成的候选记录对中，匹配的候选记录对所占的比例，s_M/(s_M+s_N)
    * PC和PQ的调和平均数
* 真实数据集
    * Cora...
    * 数据生成工具
## 第8章 总结与展望
* 基于时间模型的实体识别
* 数据缺失处理、多数据源的识别、分布式实体识别
* 分布式实体识别方法通常基于分块技术，以达到提高实体识别效率的目的。一方面，由于现实世界中数据分布，通常都是非均匀分布，导致了分块t这给分布式实体识别带来一大挑战：负载均衡问题。为了提高分布式节点的处理效率和利用率，需要


