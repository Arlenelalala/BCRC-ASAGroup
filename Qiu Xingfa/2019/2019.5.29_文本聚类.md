# 2019.5.29_文本聚类
---
* 修改和优化图数据库构建和查询代码
* 关键词纠错和消歧是一个待解决的问题
* 15%的文章未提取出任何关键词，待分析
* 初步处理了微博数据
* 看了文本聚类相关的文章和书籍，仍需进一步调研
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

---
## [Evolutionary timeline summarization: a balanced optimization framework via iterative substitution](http://delivery.acm.org/10.1145/2020000/2010016/p745-yan.pdf?ip=202.120.234.37&id=2010016&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E88014DC677A1F2C3%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1559008343_f707a179fa7f1ae06701b4ef1cac6413)

### INTRODUCTION
* Timeline temporally summarizes evolutionary news 提供发展的新闻信息
* Timeline的特征：Relevance，Coverage，Coherence，Diversity

### RELATEDWORK
* Multi-document Summarization (MDS)
* Topic detection and tracking (TDT)

### PROBLEM FORMULATION
* Input：以时间聚类的句子
* Output：发展的时间线

---
## [Event Threading within News Topics](http://delivery.acm.org/10.1145/1040000/1031258/p446-nallapati.pdf?ip=202.120.234.37&id=1031258&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E88014DC677A1F2C3%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1559025092_0d45fec43dbaa9579e2672933c760534)

### ABSTRACT
* 把识别事件和事件之间的依赖关系认定为 event threading

### INTRODUCTION
* TDT的其中一个缺点是它将新闻主题看作是故事的扁平集合

### PROBLEM DEFINITION AND NOTATION
* Story：一个故事只属于一个话题，故事是最小单元，topic -> event -> story
* Event：由一些与之相关的的故事组成，事件之间没有交集
* Topic：由一系列相关事件组成
* Topic detection and tracking (TDT) :Topic detection，将有相同话题的故事聚类；Topic
tracking：检测属于已知话题的故事
* Event threading：检测属于同一话题的事件，并判断事件之间的关系
* 存在的困难：1）事件数未知；2）事件的粒度难以定义；3）事件间的相关性难以建模；4）没有评估方法和数据

### LABELED DATA
* 如果一个同时提到两个事件，则将这个故事分配到第三个事件中，以保证每个故事只属于一个事件

### TECHNIQUES
* 把tf-idf作为其中一个特征，命名实体也是重要特征
* 将所有故事初始化为事件，故事之间的相似度由特征决定 wsum(s1，s2) = w1cos(s1，s2) + w2Loc(s1，s2) + w3Per(s1，s2)，还加入了时间衰减特征，认为时间间隔越长相似度越低，在每一次迭代中，合并相似度最接近的事件，有三种方法计算事件之间的相似度：1）事件内两两故事之间的相似度的平均值；2）事件内两两故事之间的相似度的最小值；3）事件内两两故事之间的相似度的最大值。直到事件间的最大相似度低于阈值或事件数小于指定数时，迭代停止。
* 假设所有事件之间都有关联，方向由事件内第一个故事的时间所决定，超过阈值才认为有关联

### EXPERIMENTS
* 使用平均相似度效果比单相似度要好，命名实体对事件结果并无提升，可能对话题识别更有帮助，


---
## 《面向海量文本的聚类集成技术研究》
## 第1章 绪论
> * 聚类分析可以发现无结构文本中的“潜在概念”，并用这些概念来给出文本概要或者标签
> * 文本聚类研究中存在的具有挑战性的问题：1）文本的数据是高维的，存在维数灾难；2）可扩展性；3）如何评价聚类效果。
> * 首先要解决文本的**表示**和文本**特征提取**的问题，**VSM**（向量空间模型），根据文本的加权词频统计（通常为TF-IDF）把文本表示为VSM中的一个向量，并使用余弦相似度来计算文本之间的相似度
> * 传统的聚类分析方法：
>   * 基于划分的方法：**K-Means**，采用最小误差平方和作为准则函数，随机初始化质心，然后将对象划分到距离其最近的质心所代表的簇的，随后更新质心，重新划分，如此反复，直至质心不再变化。
>     **优点**：1）空间需求小；2）时间需求小；3）在多次运行仍然高效；4）简单且可以用于各种数据类型；5）输出结果不依赖于数据处理次序。
>     **缺点**：1）K值选取困难；2）初始质心的选取对聚类结果有较大影响；3）不能处理非球形簇、不同尺寸和不同密度的簇，且对离群点或噪声点敏感
>     目前，已有许多研究者从K值的选取、初值的选取、质心更新的方式和使用三角不等式降低计算量等方面对其改进；也有一些使用分布式、并行处理等技术扩展到大型数据库中的方法，如CLARANS；还可以引入模糊思想，如FCM。特别地，针对高维文本数据，K均值算法在向量空间模型中扩展——超球K均值算法（**Sperical K-Means**）已被证明是非常的文本聚类算法，但它仍然存在K均值算法的诸多缺点
>   * 层次聚类方法：分为**凝聚的**（自底向上）和**分裂的**（自顶向下）
>       * 凝聚层次聚类算法的主要流程：1）把每个数据当成一个簇，计算临近度矩阵；2）根据预定义的距离函数，合并最近的两个簇；3）更新临近度矩阵；4）重复2、3，直到剩下K个簇。
>       * 临近度定义为不同簇之间的最小距离，得到**单链算法**，单链算法擅长处理非椭圆形状的数据，但其对噪声和离群点非常敏感。若临近度定义为不同簇之间的最大距离，称为**全链算法**，其对噪声和离群点不太敏感，对于紧密且体积大致一样的簇比较有效。若定义为点到点的平均距离，称为**组平均算法**，介于单连接和全连接之间，并且考虑了簇的大小，对噪声和离群点不太敏感。若定义为簇到簇的平均距离，称为**质心算法**。
>       * 凝聚层次聚类算法的需求空间很大，一些研究表明，层次聚类算法能产生质量较高的簇
>   * 基于神经网络的方法：最有代表性的是**SOM算法**，其功能非常强大，但其实现复杂，算法参数不易确定，且运行效率低，**不适合处理大规模文本集**。
>   * 基于密度和基于网格的方法：由于文本数据存在于高维空间，本质上是稀疏的，因此这些方法**不适合处理文本数据**
>   * 基于模型的方法：假设数据服从某个分布，而参数未知，问题转化为模型的充分统计量估计问题。优点：混合高斯模型比K均值更一般化，它可以发现不同大小呈椭球分布的簇；缺点：易陷于局部最优，计算量大，处理大规模文本时**效率非常低**。
>   * 基于信息理论的方法
>   * 谱聚类方法：优点：实现简单，结果稳定；缺点：参数设置困难，计算复杂度高
> * 聚类集成方法
> * 聚类结果评价
>   * 信息检索领域常用指标：F，熵，纯度
>   * 机器学习领域常用的指标：规范化互信息（NMI）

* 超球K均值算法（**Sperical K-Means**）
* 传统聚类分析方法输入固定，类别固定
* 新闻数据噪声较大，不同聚类体积差别大
* SOM算法
* TF-IDF

## 第2章 基于谱聚类的文本聚类集成研究方法
> * 存在的问题：
>   * 相似度图的参数设置问题：ε-近邻图，k-近邻，互k-近邻，全连通图，
>   * 进行特征值分解的矩阵选择问：正则和非正则拉普拉斯矩阵，相似度矩阵
>   * 谱聚类算法到大规模应用的扩展性问题。
> * 基于相似度矩阵的谱算法
> * 基于转移概率矩阵的谱算法

## 第3章 基于低维嵌入的文本聚类集成方法
> * 基于子空间相似度的文本聚类集成方法

## 第4章 基于非负矩阵分解的文本聚类集成方法

---
## 《基于深度学习的自然语言处理》
## 第1章 引言
> * 语言是符号化和离散的

## 第2章 学习基础与线性模型
> * **正则化**项根据参数值得出参数值的复杂度。L2正则化取参数的L2范数的平方的形式，尽力保证参数值的平方和足够小，L2正则项也称为高斯先验或者权值衰减。L1正则化取参数的L1范数的形式，尽力保证参数值的绝对值足够小，称为稀疏先验。弹性网络正则器组合了L1正则和L2正则。Dropout。
> * 凸函数是二阶导数总是非负的函数。**随机梯度下降法**也可以被用来最优化非凸函数，比如多层神经网络，虽然不能保证找到全局最优解，但该算法被证明是健壮的，实际上表现得很好。

## 第3章 从线性模型到多层感知器
> * 线性模型的假设严格受限，它不能表示异或函数
> * 核化的支持向量机或者通常的核方法通过定义一些通用的映射来解决这一问题，每个映射都将数据映射到非常高的维度空间，然后在映射后的空间中执行线性分类。核技巧的应用使得支持向量机的分类过程线性依赖于训练集的大小，使其无法应用于非常大的空间，高维空间的另一个缺点是它们增加了过拟合的风险。

## 第4章 前馈神经网络

## 第5章 神经网络训练
> * Xavier初始化
> * 随机重启
> * batch-normalization

## 第6章 文本特征构造

## 第7章 NLP特征的案例分析
> * 在作者归属任务中，特征集专注于功能词（可用高频词近似）和词性标签，对于作者来说，这是独特的难以伪造的



