# 2019.10.23

---
* 在上周的基础上，用tf-idf方法进行测试，发现目前试过的方法基本特点都是通过调节阈值可以达到一个很好的准确率，但是召回率都很差，也就是说，我们得到的事件聚类在事件内都是比较准确的，但是有可能本来属于一个事件的微博没有被分配到一起，这应该是由于中文表达的多样性或者事件发生了一些变化导致的，这是事件聚类的难点
* 在事件的聚类过程中，如何防止事件发生漂移也是一个重要问题，一条微博的错误聚类可能会导致事件整体特征的变化，会导致后续的微博无法正确聚类，尤其是在一个事件的新成立的时期，早期的事件漂移会导致更严重的后果，如何正确区分事件本身的变化或多样性和噪音的区别是一个重要的问题
* 所以在事件的代表也很重要，是否应该引入某种剔除或替换机制，对于新事件是否加入某种等待机制
* 在匹配数据中，通过直接匹配标签可以得到很好的结果，如果使用匹配数据进行训练，可能学出来的模型是类似标签匹配的东西，即使在匹配数据中得到很好的效果，也不能代表能在聚类数据上带来很好的效果
* 是否是因为标注方式的原因？
* 匹配分类思路是否可行？
* 如果使用目前标注的数据集进行训练，是否需要一个新数据集进行测试？
<br>
<br>
<br>
<br>

---
## [StoryMiner: An Automated and Scalable Framework for Story Analysis and Detection from Social Media](https://escholarship.org/content/qt9637m3j1/qt9637m3j1.pdf?t=pwzuo0)
### ABSTRACT OF THE DISSERTATION
* StoryMiner derives stories and narrative structures by automatically 
    * extracting and co-referencing the actants (entities such as people and objects) and their relationships from the text by proposing an Open **Information Extraction** system, 
    * assigning named-entity types and importance scores for entities and relationships using character-level neural language architectures and other traditional machine learning models, 
    * making use of context-dependent word embeddings to aggregate actant-relationships and form contextual story graphs in which the nodes are the actants and the edges are their relationships, and 
    * enriching the story graphs with additional layers of information such as sentiments or sequence orders of relationships.

### Introduction
* the main theme of this research is to introduce a narrative framework which is capable of identifying and representing narrative structures and contents from a large corpus of text

---
## [Adaptive Multi-Attention Network Incorporating Answer Information for Duplicate Question Detection](http://delivery.acm.org/10.1145/3340000/3331228/p95-liang.pdf?ip=202.120.224.53&id=3331228&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E88014DC677A1F2C3%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1571709823_661dc7afae46acce82bc80b96e3b56ab#URLTOKEN#)

### ABSTRACT
* we propose an answer information-enhanced adaptive multiattention network to detect duplicate questions
* To obtain multi-level textual features, we use the concatenation of word embedding, character embedding, and syntactical features as the representation
* we utilize three heterogeneous attention mechanisms: **self-attention**, which facilitates modeling of the temporal interaction in a long sentence; **cross attention**, which captures the relevance between questions and the relevance between answers; and **adaptive co-attention** which extracts valuable knowledge from the answers.

### EXPERIMENT
* datasets：In addition to CQADupStack, we expand the Quora Question Pairs (QQP) dataset with the paired answers and named it the answerenhanced QQP (AeQQP).

### 思考
* 论文主要解决的是问句的语义匹配问题，加入了答案的信息，为降低负面影响，引入了几种注意力机制，作为一个二分类问题
* 去除注意力机制之后效果下降，表示注意力机制的有效性
* 微博正文也可考虑评论或转发信息，但对于及时性运算速度，影响很大

---
### [Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement](https://www.aclweb.org/anthology/N16-1108.pdf)

* Most previous work use sentence modeling with a “Siamese” structure
### Model Overview
* Bidirectional Long Short-Term Memory Networks (**Bi-LSTMs**) are used for context modeling of input sentences, which serves as the basis for all following components.
* A novel **pairwise word interaction modeling** technique encourages direct comparisons between word contexts across sentences.
* A novel **similarity focus layer** helps the model identify important pairwise word interactions across sentences.
* A 19-layer deep convolutional neural network (**ConvNet**) converts the similarity measurement problem into a pattern recognition problem for final classification.
* this is the first neural network model, a novel hybrid architecture **combining** Bi-LSTMs and a deep ConvNet, that uses a **similarity focus mechanism** with selective attention to important pairwise word interactions for the STS problem.


