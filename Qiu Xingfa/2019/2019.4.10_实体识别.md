# 2019.4.10_实体识别

---
* 主要把项目相关代码整理了一下上传到了svn上，事件库目前可以做到十分钟更新一次，尽量和爬虫端同步，保留七天数据，删除七天之前的数据
* 关于同一事件的分类，手动标注了一千条数据，打算用来做文章聚类的评估
* 正在看《实体识别技术》，书写的一般，主要是这本书所描述的实体识别任务和事件聚类有点像，书中对于实体的定义和一般命名实体不同，命名实体更多是对于词的概念，而书中的实体则是文章、商品等等更为普遍的定义，实体识别就是在大量脏数据中把实体找出来，区分开
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

---
## 《实体识别技术》
## 第2章 相似度计算算法
> * Jaccard相似度计算方法；基于TF-IDF的相似度算法；基于q-grams的相似度算法（比较适用于存在拼写错误的字符串间的比较）；基于编辑距离的相似度算法；混合的相似度算法
> * 数值型相似度算法

## 第3章 实体识别的分块技术
> * 数据分块就是一种通过尽可能减少需要进行具体比较操作的记录对数量来提高实体识别效率的技术。
> * **基本思想**是将数据集合基于分块标准划分为多个小的数据块，其中有可能匹配的两个记录会划分到相同的数据块中，然后再对每个数据块内的记录进行两两成对比较，从而找真实匹配的记录对。
> * 基于等值匹配的分块算法，基于相似性的分块算法
> * 很多情况下，实体识别数据分块依然采用**人工定义**的方法
> * 标准分块方法的一种有效实现方式是使用倒排索引这种数据结构
> * 基于学习的分块键定义（转换为一个等价于红蓝集合覆盖的问题）
> * q-grams的分块方法并不适合于具有长文本属性的大规模数据上的实体识别分块处理
> * 对于数据分块方法而言，要求其执行代价必须尽可能小，以便能在很大的数据上运行

* 目前事件聚类算法，实际上分块键定义为人名，地名，机构名等关键词，有共同特征的文章才会进行相似度计算，相当于等值匹配的分块算法

## 第4章 基于机器学习的实体识别方法
> * 基于分类器的实体识别方法：
> **首先**建立一个初始的实体识别模型，
> **然后**，利用训练数据集对该模型进行反复训练，
> **逐渐地**，模型在训练中能够学习到“如果哪些属性相似，那么记录对匹配的概率会更大”，“应用哪种匹配函数会得到与标记结果更加类似的识别结果”，“记录之间的相似度要达到什么程度，才能认为它们是匹配的”等内容，
> **最终**将这些学习到的参数、函数以及规则应用于实体识别模型中，以提高实体识别的准确度。
>   * 基于**决策树**的实体识别方法：1.生成训练集；2.基于CART算法生成匹配规则（基尼指数）；3.基于模型选择策略降低复杂度
>   * 基于**贝叶斯分类器**的实体识别方法：实体识别问题可以用分类的方法加以解决，其类别标记为“匹配”或“不匹配”

---
##《情感分析：挖掘观点、情感和情绪》

## 第1章 引言
> * 根据处理文本的粒度，情感分析可以分为篇章级、句子级和属性级三个级别
> * 情感词的倾向性往往会随着其应用领域以及其所在的上下文的变化而变化；一个句子即使出现了情感词，也不一定会表达任何情感；讽刺句是很难处理的句式，无论其中是否出现情感词；很多情况下一个句子可能不会出现情感词，但依然可能隐含了作者的观点。
> * 垃圾观点发布

## 第2章 什么是情感分析
> * 当前的商业系统可以对产品服务的方面做出很好的分析，却对社会和政治类文本束手无策
> * 观点是一个五元组（e,a, s, h, t),分别是观点评价目标实体，实体属性，情感，观点持有者，时间
> * 情感是一个三元组（y，o，i）,分别表示情感的类型、倾向和强度
> * 情感分析的目标是找出文档中的五元组
> * 主要任务：实体抽取和消解，属性抽取和消解，观点持有者抽取和消解，时间抽取和标准化，属性情感分类和回归，生成观点五元组，观点原因抽取和消解，观点限定条件抽取和消解。

* 新闻信息抽取也是抽取一个n元组，包含一些比较重要的新闻元素，**新闻六要素**：时间，地点，人物，事件的起因，经过，结果，而**新闻的结构是**：标题，导语，主体，背景，结语，新闻要素是分开抽取还是一起抽取？要素是否要进行消歧，如何进行消歧，标题往往包含了一些关键信息（是否充足），标题实际上是文本内容的高度总结，同时也会有一些观点的倾向性

---
* 知识嵌入训练结果

|metric:|			 MRR| 		 MR| 		 hit@10| 	 hit@3|   hit@1 |
|---|---|---|---|---|---|
|l(raw):|			 0.000800| 	 3379163.250000| 	 0.001177 |	 0.000736 |	 0.000500 |
|r(raw):	|		 0.128256 |	 1237876.375000 |	 0.269142 |	 0.147666 |	 0.052057 |
|averaged(raw):	|	 0.064528 |	 2308519.750000 |	 0.135160 |	 0.074201 |	 0.026279 |
|l(filter):	|	 0.000857 |	 3115953.250000 |	 0.001295 |	 0.000795 |	 0.000530 |
|r(filter):	|	 0.150462 |	 1237875.875000 |	 0.272115 |	 0.147961 |	 0.092726 |
|averaged(filter):|	 0.075659 |	 2176914.500000 |	 0.136705 |	 0.074378 |	 0.046628 |
type constraint results:
|metric:|			 MRR| 		 MR| 		 hit@10| 	 hit@3|   hit@1 |
|---|---|---|---|---|---|
|l(raw):	|		 0.008005 |	 1914725.875000 |	 0.011653 |	 0.008387 	| 0.005944 |
|r(raw):		|	 0.174226 |	 321461.312500 |	 0.331205 |	 0.189954 |	 0.103731 |
|averaged(raw):	|	 0.091115 |	 1118093.625000 |	 0.171429 	| 0.099170 	| 0.054838 |
|l(filter):	|	 0.008451 |	 1651496.875000 |	 0.012359 |	 0.008916 |	 0.006297 |
|r(filter):	|	 0.198413 |	 321460.625000 	| 0.334295 |	 0.191219 |	 0.147490 |
|averaged(filter):|	 0.103432 |	 986478.750000 	| 0.173327 |	 0.100068 |	 0.076894 |

triple classification accuracy is 0.805943



