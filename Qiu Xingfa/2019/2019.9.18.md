# 2019.9.18


---
## 数据标注
* 根据2019年8月1日至8月7日的微博，抖音，头条的热搜，挑选出754个标签（或关键词），将这些标签分成285个事件，按照这些标签或关键词在ES数据库中搜索包含这些关键词的历史数据，得到539856条数据
* 有些事件的粒度很大，如香港相关的事件，有十几万条数据，有些事件粒度很小，如“伊朗扣押外国油轮”，有13条数据，一方面是对于事件来说，挑选的关键词不够多，可能有同一事件不同标签没有考虑到
* 除去转发微博，剩余450117条数据，除去无评论的微博，剩余175089条数据
* 设置每个事件的微博上限，以500为上限，剩余59847条数据，以100为上限，剩余22561条数据
* 选取评论数靠前的100条微博
* 标注这两万多数据，将异常值去除，标注未完成
<br>

* 存在一些问题：根据数据标注方法，这更像是标签的聚类而不是微博的聚类，因为微博热搜基本都是有对应标签的，根据这个去搜索到的微博更多是带有这个标签的数据，如果用一个标签表示一个事件的话，那聚类就没有意义，另外，很多微博更像是对事件的评论，也就是只有标签上有事件信息，如“#黄毅清被停止拘留后发文#人丑戏多 ”
* 如果是这样的数据的话，我觉得重点可以放在 ，**单标签和多标签微博的聚类**，无标签微博的关键词提取，至于一个标签处于不同事件和标签随时间变化，从标注的角度来说，比较难找这样的数据
* 我们无法标注全部数据，所以数据的选取和标注一定程度会影响我们的方法
* 七天可能不太具有代表性，时间长了标签可能会随时间变化
<br>
<br>
<br>

* 接下来先试着把数据标注完，做做实验，后续再看是否需要扩充事件的标签或关键词
* 继续调研

## 项目
* 对于排序，增加了白名单和黑名单，白名单词语来自于过去24小时新闻的高频关键词和自己定义的名单，黑名单为自己定义，白名单增加权重1~1.5，黑名单权重为0
* 考虑新爬的数据，使得热度计算时的评论数等数据接近当前时间
* 和前端对接，按小时存储热度数据，排行数据等



---
## [STREAMCUBE: Hierarchical Spatio-temporal HashtagClustering for Event Exploration over the TwitterStream](https://kopernio.com/viewer?doi=10.1109/ICDE.2015.7113425&route=6)

* 提出问题：
    与一般的文档不同，推特可能提供地理信息和话题信息，从而可以从不同的空间粒度和时间粒度发现事件
* 贡献
    * 对于推特数据流的一个分层的时空粒度的话题聚类
    * 从不同的空间粒度和时间粒度发现事件
    * 使用高效的单遍遍历算法，提供可理解的聚类标签
    * 在一个特定的时空条件下进行有效的事件排序，发现爆炸事件或局部的事件
    * 与传统方法不同，本文从推特流中实时地处理数据
    * 递增地将新数据与旧数据融合，
* 方法
    * 由三个部分组成，1）时空聚类；2）单遍遍历的话题标签聚类；3）事件排序
    * 事件就是标签的集合，而标签是随时间变化的，基于标签的聚类具有可解释性
    * 考虑时间和空间粒度，将数据划分到一个时空之内进行小范围的聚类，
    * 在时间和空间上构建quad-tree，每次四等分，三层，只把最近6小时的数据当作流入的新数据（`类似三位编码`）
    * 标签的表示方法：1）所有使用当前标签的推特文本集合；2）多个标签的集合表示，55%的文本有多个标签，多标签是用户提供的标签聚类
    * 用标签的word vector 和 hashtag vector 的加权余弦相似度来表示相似度，事件的表示和相似度计算类似。
    * 标签和事件都是随时间变化的
    * 对于静态的标签（假设标签不变）聚类，为了减少计算量，只把和当前标签有共同部分的聚类作为候选（`对于单标签的数据不友好，会漏掉很多不共现的标签`），如果当前标签和最近邻事件的相似度小于当前事件和其他事件的最小相似度，那就应该成立一个新事件（`初始相似度阈值如何定义，标签和事件的相似度和事件之间的相似度是否有可比性`）
    * 对于变化的标签，新标签出现时，先当作不活跃的新事件，超过30条推特标签变为活跃状态，每三十次更新检查聚类是否需分裂或融合（`计算量较大`）
    * 按照 热度，突发性和局部性 对事件排序，通过有监督的训练，得到权重值
* 数据
    * 获取900万条推特，有200万标签，时间为从2013年12月到2014年1月，没有地理位置标签的使用用户位置来代表或随机采样（`不合适`）
    * 对比不同方法选出的top5事件（`对于一个事件，也就是标签的集合，如何选出一个代表的标签`）
    * 融合不同方法选出的top50标签作为候选，让十个人投票选出top10
* 存在问题
    * 对于无标签和单标签的数据不友好
    * 计算聚类质量的时候，ground truth的产生方法存疑，250个标注事件是如何标注的，对于变化的标签以及变化的事件是如何评估的，如何体现动态聚类的结果
    * 流式数据是连续的，强行切分会导致切分点附近的数据不连续，如果只做一次聚类，那一个标签可能会在几个部分中存在，那是如何分配的呢
    * 标签是很重要的信息，如何利用标签信息，如何处理无标签，单标签，多标签的关系，标签的粒度也是不一致的，如何体现标签的变化（取最近一段时间的文本表示）

---
## [Event Detection and Retrieval on Social Media](https://arxiv.org/pdf/1807.03675.pdf)
* 三个主要类别：1）新闻相关；2）娱乐事件；3）个人事务
* 大量的噪音和无意义的内容使得这项任务变得困难，有些事件会有大量的与之相关的文本，从中选出信息丰富的具有代表性的文本也是一项具有挑战性的工作
* 事件检测的三种方法：
    * 基于特征的
        * 特征可以从关键词，命名实体到社交
        * 基于特征的时间分布
        * SVM分类器
    * 基于文本的
        * 使用贝叶斯分类器判断是否新闻，TF-IDF表示tweet
        * 词汇的多样性使得同一事件出现不同的词语，在微博客上这种现象更加明显
    * 主题模型
        * 对于社交媒体的处理，不仅把词语当作可观测量，还要考虑用户，图片信息，发布时间和地址等信息，对于短文本来说，一个文本是许多话题的集合的假设可能有点问题
        * LECM（Latent Event and Category Model）：包含相同的命名实体，关键词，相近的时间和地点更可能是同一事件
* 简短，非正式，不合乎文法的文本使得社交媒体的摘要变得更加困难
* 评估
    * P，R，F1
    * NMI（Normalized Mutual Information）
    * 摘要：ROUGE
    * 定性分析
    * recall较难计算

* 有几篇相关文献需要阅读
    

    



