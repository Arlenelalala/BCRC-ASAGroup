# 2019.6.19

* 对图数据库存储方式和聚类代码进行了较大程度的改动和优化，完成了故事->事件->文章三级结构<br>
![](https://github.com/qiuxingfa/picture_/blob/master/2019/db9b9c6cbeec0a90c9007e8541e00d4.png)<br>

每一层训练了简单的SVM分类模型进行聚类，考虑了标题、关键词、命名实体和时间等特征，并对关键词特征进行了拼接处理

* 读了一本书《大数据搜索引擎原理分析》，搜索引擎的对文本的处理方式和新闻的处理方式很相似，包括分布式爬虫、大数据存储、基本的自然语言处理，排序和推荐等等

* 存在的一些问题以及接下来的计划
    * 聚类算法的效率不够高，想办法提升聚类算法的效率，数据库层面和算法层面
    * 继续对聚类算法进行调研和优化
    * 整理最近的工作

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

---

## 《大数据搜索引擎原理分析》
## 第3章 自然语言处理框架
> * 关键词提取常用的方法是TF-IDF算法，另一种自动化抽取方法是采用词语权重（TextRank）
> * TF = 该词在此文件中出现的次数/文件中所有字词的出现次数之和；IDF = log（文件总数/包含词语i的文件数）
> * 权值 TF × IDF
> * TF-IDF的实现基于“对区别文档最有意义的词语应该是那些在文档中出现频率高，而在整个文档集合的其他文档中出现频率较低的词语”的假设条件。单词位置依然是非常关键的信息，例如在标题中的关键词权重应当高于在正文内部的关键词权重，正文首尾段落单词的权重应当高于正文中部单词的权重。
> * 对于需要比较的两篇文档，可以通过提取各自的关键词，先利用关键词进行词频统计，再利用余弦相似度进行计算。另一种方法是采用w-shingling算法，算法中的集合是文档内容中的有序序列，采用N-gram的方式提取句子中的有序序列。
> * 在文本聚类算法中，最直接的是K-Means算法，它是一种自下而上的聚类分析方法。**缺陷**：1）对异常值、摇摆值比较敏感，导致收敛速度变慢；2）需提前确定K值。在多数情况下，聚类算法的效果评估需要与实际业务问题相结合，然后进行综合评估。
>   * 在**没有标注**数据的情况下，1）基于紧密性；2）基于间隔性；3）基于戴维森堡丁指数（计算任意两个类别的类内距离平均距离之和除以两聚类中心距离，指数越小越好，对于环状聚类的评估效果较差。）；4）基于邓恩系数（任意类间的最短距离除以任意类内的最大距离），对于环状分布的点，邓恩指数评估效果相对一般。
>   * 在**给定标注**数据的情况下，1）基于准确性评估；2）基于兰德指数；
> * 在实际对聚类效果的评估过程中，更多的情况是基于内部的方式评估聚类效果；基于已有标注样本进行聚类评估实际上是一种基于先验知识或假设的评估方式，在实际场景中较少使用。

## 第4章 构建大数据存储引擎

## 第5章 构建分布式实时计算

## 第6章 分布式可扩展爬虫
> * 主从分布式结构爬虫；对等分布式结构爬虫；基于分布式计算平台爬虫；
> * 使用布隆过滤器进行去重
> * 采用Adblock plus的思想对广告进行拦截
> * Simhash算法进行相似度比较

## 第7章 大数据构建知识图谱
> * 基于模式匹配的**关系抽取**方式，处理英文可以得到很好的效果，但对于丰富、灵活的中文，虽然提取准确率较高，但覆盖率却比较低，且过于依赖模式，不够灵活，在少量数据集上（如实验室测试）采取这种方式可以得到较好的结果，而对于搜索引擎数亿级的海量数据抽取则不太合适。
> * **核函数**将特征从低维转换到高维，但依然在低维进行计算，虽然表现形式展现为多维，但是避免了在高维上直接进行复杂的数学计算，因此支持向量机对于非线性分类有很大优势。
> * **实体对齐**：先通过聚类的方式，将可能相似的实体放在一个聚簇空间，再通过相同的属性索引进行实体比对。
> * **实体消歧**：关键词权重
> * **知识聚类**：DBSCAN是一种基于密度的聚类算法，思想：在以某点为核心点的基础上，在指定半径范围内，拥有超过指定的点数量，则形成一个聚簇。这种聚类算法不需要指定聚类数量，缺陷：不能很好地反映高维数据，在聚类密度不断变化的数据集中，不能很好地反映整体的聚类情况。
> * **智能搜索**：1）模式匹配；2）知识拆解；3）合并求解
> * **问答系统**：1)IR-Based QA;2)Community QA;3)KB-Based QA

## 第8章 索引构建机制
> * 在工程应用中，实际上并不会存储所有关键词对应的文档，某个关键词对应的文档不会超过20万个。

## 第9章 搜索服务构建
> * 当前搜索引擎，通常会将用户的搜索提问归纳为“5W2H”，俗称**七何分析法**，What,How,Why,When,Where,Who,How Much
> * **文本纠错算法**：使用N-gram语言模型判断是否出错，而采用词库的方法进行纠错导致计算复杂度高，采用最短编辑距离是一种比较可行的方式
> * **网页排序**：
>   * PageRank:d为阻尼系数，一般为0.85
>   * 基于HITS算法的网页权威性评价
>   * HillTop算法
> * **个性化搜索**：保存两大模型，用户模型和词语特征模型，用关键词对应的词语特征与用户特征相乘作为输入，输出为网页的个性化权重。
> * **搜索与广告**：寻找相似用户的基本思想借鉴了KNN算法的思想，KNN算法通过一种类似于投票的方式来决定需要投放的广告，但是这种看似公平、民主的算法其实有一个问题：当数据分布相对较为均匀，且密度较为集中时，K的不同取值将会导致目标数据的分类波动。基于混合模式的广告投放model-based，item-based，user-based，
> * **搜索引擎评价**：1）结果的准确率；2）结果的全面性；3）结果的时效性；4）检索方式的多样性；5）搜索时间相应。NDCG

* 事件元素也是七何
* 推荐也可以保存用户模型，词语特征模型，甚至事件模型话题模型

## 第10章 基于用户日志的反馈学习

---

## [Discovering Event Evolution Graphs From News Corpora](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4909011)

### INTRODUCTION
* Topic Detection and Tracking（TDT）

### RELATED WORK
* TDT包括story segmentation, topic detection, new event detection, link detection, and topic tracking
* Allen通过相似度计算判断文档是否属于之前的类别；Yang使用自然语言处理技术提取关键词和命名实体；Makkonen首先将事件发展作为TDT的子任务，但没有进行清晰的定义和实验；Mei和Zhai将问题定义为主题发展；Nallapati认为event threading是树状结构
* 之前的研究很少对话题或者事件之间的关系进行建模
* Event evolution是区别于TDT的新的概念
* Makkon发现地址和命名实体特征对于将故事聚类成事件没有效果

### EVENT EVOLUTION
* story：假设每篇文章只描述一个故事，而每个故事只描述一个事件，故事是最小环节
* 如果B事件的发生取决于A事件的发生，则AB具有发展关系

### CONSTRUCTING EVENT EVOLUTION GRAPHS
* 1）生成事件；2）建模事件之间的关系；3）删除无效关系
* 手动地生成事件
* 事件向量以故事平均TF-IDF生成

---

## 社交媒体自然语言处理
## 第一章 社交媒体分析概述

## 第二章 社交媒体文本语言预处理
> * 让自然语言处理工具适用于社交媒体文件的处理，
>   * 一个是进行文本标准化，1)在输入文本中识别拼写错误；2）纠正识别出的错误
一个是在社交媒体文本上重新训练自然语言处理模型

