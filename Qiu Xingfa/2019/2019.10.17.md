# 2019.10.17

---
## 微博数据实验
* 在已标注的微博数据进行实验，使用字符的相似度来进行计算，使用不同方法来代表事件和标签
* 之前的想法是通过 微博-事件 的数据对来进行相似度比较，作为一个分类任务，但是经过初步实验发现一些问题，
    * 标注数据存在一个假设就是在进行相似度比较时事件是**完全准确**的，加上数据是通过标签进行标注的，那么通过提取当前微博标签和事件微博标签，然后直接进行匹配，在匹配数据集中可以达到0.95以上的准确率和召回率，用匹配数据进行评估并不准确
    * 实际情况中，正例和负例的数量极其不平衡，随机挑选的负例可能不会对分类造成影响，但是在实际聚类中，每一个事件都会和当前微博进行相似度计算，分类错误的可能性大大增加，试过将正负比例调到1：10，F1依然很高，但这种方法在聚类数据的评估效果很差，所以说即使在匹配数据得到一个很好的结果，也不能代表在聚类中就能得到一个很好的结果
    * 问题主要在于在实际聚类过程中，会出现漂移现象，即可能一次分类错误会导致后面的错误越来越严重，事件下的微博可能已经很难维持一个事件的特征了，尤其是事件新产生的阶段，解决办法为充分地利用事件信息，减少分类错误的情况发生
    * 如果匹配数据无法很好的评估聚类性能的话，那就只能用整体数据来评估。但如果用聚类数据来做有监督训练的话，是否有必要再标注一个测试集？
## 一部分结果
* 数据1为1：1的匹配数据，数据2为1：10的匹配数据，方法为当前微博最长标签和事件所有标签的匹配
|数据|P|R|F1|
|---|
|1|0.9929|0.9723|0.9825|
|2|0.9286|0.9679|0.9478|


* 在聚类数据集中
|方法|P|R|F1|purity|entropy|NMI|
|---|
|1|0.2241|0.2307|0.2372|0.7941|0.9175|0.7984|
|2|0.8603|0.1623|0.2731|**0.9261**|0.2701|0.8385|
|3|**0.9799**|0.0265|0.0517|0.3839|**0.0419**|0.8486|
|3|0.9545|0.0430|0.0823|0.4541|0.0871|0.8600|
|4|0.9123|0.3828|0.5393|0.8733|0.2574|0.8985|
|5|0.8326|0.5071|0.6303|0.8165|0.5310|0.8916|
|6|0.8953|0.4083|0.5609|0.8347|0.3418|**0.9001**|
|7|0.7579|**0.5748**|**0.6538**|0.7510|0.7384|0.8798|

方法1：当前微博以最长标签为代表，匹配事件所有标签
方法2：当前微博以最长标签为代表，匹配事件内出现频率前五的标签
方法3：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算Jaccard相似度，0.3为阈值
方法3：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算Jaccard相似度，0.2为阈值
方法4：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算字符相似度，0.3为阈值
方法5：当前微博以最长标签为代表，事件以所有标签拼接为代表，计算字符相似度，0.2为阈值
方法6：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算字符相似度，0.3为阈值
方法7：当前微博以最长标签为代表，事件以所有微博的最长标签拼接为代表，计算字符相似度，0.2为阈值

* 计划
    * 继续使用无监督方法在已标注数据上进行测试
    * 准备用有监督方法训练匹配数据，然后用整体数据评估
    * 继续调研


---
## [TwitterNews: Real time event detection from the Twitter data stream](https://www.researchgate.net/profile/Mahmud_Hasan8/publication/309426330_TwitterNews_Real_time_event_detection_from_the_Twitter_data_stream/links/581a12b008aeffb294130fd1/TwitterNews-Real-time-event-detection-from-the-Twitter-data-stream.pdf?_sg%5B0%5D=TnznRnCrOp6ZZclRyRwcqEB4IIRkbOvPhDGOkLY403iD2TAh87WNHmQ3YgnlhW8H_kxDJ4o4zW7AvOJIUF_s6Q.rvivN9t4tv9QsIZ-bRsBICXS9YUkxh3FnhWYdRYuE0aqJQP9dlN752umgbo-SgQC6Or5VYV4nH1rhlxVQ0vbrQ&_sg%5B1%5D=W7u992XqavOYSoexjseJ7Q97t4XvzkCJC-9DGowiktOVZ4moje8qyeerx2nuRO5dB9wPyEYIS7EGMEmtYDwb_bLE83W_ZeQ7AW1GznnRG27r.rvivN9t4tv9QsIZ-bRsBICXS9YUkxh3FnhWYdRYuE0aqJQP9dlN752umgbo-SgQC6Or5VYV4nH1rhlxVQ0vbrQ&_iepl=)

### Abstract and Introduction
* **TwitterNews** provides a novel approach, by combining random indexing based term vector model with locality sensitive hashing, that aids in performing incremental clustering of tweets related to various events within a fixed time.
* **definition of an event**: An occurrence causing change in the volume of text data that discusses the associated topic at a specific time. This occurrence is characterized by topic and time, and often associated with entities such as people and location
* The approaches based on **term interestingness** and **topic modeling** suffer from high computational cost among other things
* we propose an incremental clustering based end-to-end solution to detect newsworthy events from a stream of time ordered tweets
* ![](https://github.com/qiuxingfa/picture_/blob/master/2019/503e217a772d365266fb56b078e0e4b.png)
* **The operation in the first stage** of TwitterNews is implemented by combining Random Indexing (RI) based term vector model with the Locality Sensitive Hashing (LSH) scheme proposed by Petrovic et al. to determine whether a tweet is “not unique”. 
    * Using the **Search Module** we aim to detect a soft burst, that is, we intend to find at least one previous tweet that discusses the same topic as the input tweet
    * A **fixed number** of hash tables are maintained to increase the chance of finding the nearest neighbor of the input tweet.
* Subsequently **the second stage**, implemented using a novel approach by adapting the generic incremental clustering algorithm, deals with generating the candidate event clusters by incrementally clustering the tweets that were determined as bursty (“not unique”) during the first stage.The second stage also incorporates a **defragmentation strategy** to deal with the fragmented events that were generated when a particular event is detected multiple times as a new event.
* **Finally** a set of filters are applied after the second stage to report the newsworthy events from the candidate event clusters

### Related Work
* Term Interestingness Based Approaches(``often capture misleading term correlations, and measuring the term correlations can be computationally prohibitive in an online setting``)
* Topic Modeling Based Approaches (``incur too high of a computational cost to be effective in a streaming setting, and are not quite effective in handling events that are reported in parallel``)
* Incremental Clustering Based Approaches (``are prone to fragmentation, and usually are unable to distinguish between two similar events taking place around the same time``)
    * Becker et al . For each tweet, its similarity is computed against each of the existing cluster.Once the clusters are formulated, a **Support Vector Machine** based classifier is used to distinguish between the newsworthy events and the non-events
    * McMinn et al.  have utilized an **inverted index** for each named entity with its associated near neighbors to cluster the bursty named entities for event detection and tracking
    * Petrovic et al.  have adapted a variant of the **locality sensitive hashing** (LSH) technique to determine the novelty of a tweet by comparing it with a fixed number of previously encountered tweets

### Experiment Results and Evaluation
* **Corpus**： Events2012 corpus provided by McMinn. The corpus contains 120 million tweets from the 9th of October to the 7th of November, 2012. Along with this corpus 506 events, with relevant tweets for these events, are provided as a ground truth
* we have only reconfirmed the first three days (9th to 11th of October, 2012) of the ground truth events and manually selected a total of 41 events that belong to our selected time window
* We have used the LSH scheme proposed by Petrovic et al.  as our baseline
* TwitterNews achieved a recall of 0.87 by identifying 27 events out of the 31 ground truth events. The precision is calculated as a fraction of the 100 randomly chosen events that are related to realistic events.
        
### 思考
* 和很多其他论文一样，本文将事件提取分为两个阶段，第一阶段进行事件的发现，第二阶段进行事件聚类
* 文章说用ti-idf计算相似度开销大，使用RI向量加快计算速度，因为这个向量是定长的，词向量也有这个特征，可使用矩阵乘法进行相似度计算，不过矩阵的维护和更新也会影响计算速度，
* 每个事件只选取一条推特，可能不具有代表性
* 作者在第一阶段选择计算历史推特和当前推特的相似度，超过一定阈值才进入下一阶段，历史推特维持一个固定值，这个方法的计算开销也很大，如果把独立的推特当成独立的事件，直接计算推特和事件的相似度，合并两个阶段，计算量小的同时也能达到这样的效果，不过这种方法的优点是会减少事件的数量，不是所有推特都形成事件，只有在一定的时间窗口内有多条推特讨论时才考虑进行事件的聚类，这对于**讨论较少**的事件和**间隔较长**的事件不友好，这和数据窗口的长度（需指定）以及数据的完整有很大的关系
* 通过LSH（Locality Sensitive Hashing）方法优化较少计算量的方法值得进一步调研
* 作者也将事件设置了一个有效期（8-15分钟），时间有点短，但是时间一长容易导致事件数太多
* 作者的评估方法存疑，31个事件中识别出16个事件则召回率为0.52，认为识别出一个事件的标准是什么？和ground truth有多少重叠认为是同一事件？准确率也是根据随机挑选的100个事件来计算的，并不合理

---
## [Streaming First Story Detection with application to Twitter](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.9438&rep=rep1&type=pdf)
### Introduction
* the goal of FSD is to identify the first story to discuss a particular event
* The traditional approach to FSD, where each new story is compared to all, or a constantly growing subset, of previously seen stories, does not scale to the Twitter streaming setting
* Allan et al. (2000) report that this distance（cosine） outperforms the KL divergence, weighted sum, and language models as distance functions on the first story detection task.
* ![](https://github.com/qiuxingfa/picture_/blob/master/2019/b0f3cacad9f3fb7003e3de2de0afd82.png)
* In the context of first story detection, this means we are not allowed to store all of the previous data in main memory nor compare the new document to all the documents returned by LSH.

### Experiments
* TDT5
* We compare the systems on the English part of the TDT5 dataset, consisting of 221, 306 documents from a time period spanning April 2003 to September 2003.
* Data was collected through Twitter’s **streaming API**. Our corpus consists of 163.5 million timestamped tweets, totalling over 2 billion tokens
* we employed two human experts to manually label all the tweets returned by our system as either Event, Neutral, or Spam.we only labeled the 1000 fastest growing threads from June 2009

### 思考
* FSD需比较当前文档和历史文档的相似度，当最小距离大于阈值时，则认为是新事件，其实这也是事件聚类的一部分，可以分开做也可以一起做。
* 数据不可能是无限的，所以论文在很多地方设置了上限，如历史推特的比较数，
* LSH的基本思想是：将原始数据空间中的两个相邻数据点通过相同的映射或投影变换（projection）后，这两个数据点在新的数据空间中仍然相邻的概率很大，而不相邻的数据点被映射到同一个桶的概率很小。

---
## [ELD: Event TimeLine Detection - A Participant-Based Approach to Tracking Events](http://delivery.acm.org/10.1145/3350000/3344921/p267-mamo.pdf?ip=65.49.38.140&id=3344921&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1571052520_5df392b95790ecb98b40e864b95da3ad)
* ELD’s inputs do not only include a seed set of keywords that describe the event , but also the lengths of two time windows. In the **first time window**, ELD uses the user’s seed set to collect tweets that shape its understanding of the event. In the **second time window**, ELD uses this understanding to follow the event and build its timeline
* we use this dataset to build Reed et al.’s Term Frequency- Inverse Corpus Frequency (**TF-ICF**) instead
* FIRE adopts a traditional incremental clustering algorithm as the　**document-pivot** approach. Incoming tweets join the most similar　cluster if the similarity exceeds a threshold; otherwise, they form　a new cluster.

### 思考
* 作者没有用TF-IDF，而是用的TF-ICF

---
## [Event Discovery in Social Media Feeds](http://aria42.com/pubs/events.pdf)
### Abstract
* We develop a **graphical model** that addresses these problems by learning a latent set of records and a record-message alignment simultaneously   

### Problem Formulation
* **Message**: a single posting to Twitter
* **Record**: A record is a representation of the canonical properties of an event (Throughout, we assume a known fixed number K of records)
* **Message Labels**: We assume that each message has a sequence labeling
* ![](https://github.com/qiuxingfa/picture_/blob/master/2019/d3bf4e8b313304f4403f856495045ab.png)

### Model
* ![](https://github.com/qiuxingfa/picture_/blob/master/2019/d949e4c11ec344a081afae931a9fb44.png)
* One challenge with Twitter is the so-called **echo chamber effect**: when a topic becomes popular, or “trends,” it quickly dominates the conversation online. As a result some events may have only a few referent messages while other more popular events may have thousands or more.

### 思考
* 推特中的每一个词都有表示事件属性的标签




