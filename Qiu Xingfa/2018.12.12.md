# 2018.12.12
----
* 爬虫部分
    微博搜索、评论、转发，用户微博、基本信息，百度百科基本信息初步可运行的代码都已经写好，微博社区管理中心约一万条不实信息已经爬好
* 看了几章 [《深度学习框架PyTorch：入门与实践》](https://github.com/chenyuntc/PyTorch-book)
* 看了论文 [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf)，提出了ELMo模型，即Embeddings from Language Models的结构，对于论文中所描述的动态embedding的原理还不清楚，打算找其他资料或者原代码看看

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
---

## [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf)<br>

* ELMo模型（Embeddings from Language Models）在question answering, textual entailment 和 sentiment analysis等六项任务中达到state of the art(2018年2月）<br>
    ![](https://github.com/qiuxingfa/picture_/blob/master/2018.11/bcf800a60a6468b3678aac9378e7878.png)<br>
* 高质量的representation应该包括
    * 复杂的词语特征（语法和语义）
    * 在不同语境下有不同的作用
* 带字卷积的两层的双向语言模型<br>
    ![](https://github.com/qiuxingfa/picture_/blob/master/2018.11/fa4664c0f2da7f8520727c59222267c.png)<br>

>每一个词语的表征都是整个输入语句的函数，具体做法就是先在大语料上以language model为目标训练出bidirectional LSTM模型，然后利用LSTM产生词语的表征。

并不是完全独立的双向语言模型，两个方向共享了一些参数（？），ELMo将所有参数放到一个单独的向量里，进行了一些规范化处理，biLM对于每一个输入token都提供了三层的representations，实验结果显示只用最后一层的representation效果比三层都用的效果要差一点 ，
* 文章认为低层和高层的LSTM功能有差异:低层能够提取语法方面的信息;高层擅于捕捉语义特征
    




