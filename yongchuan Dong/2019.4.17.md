# **论文**

**Cloze-driven Pretraining of Self-attention Networks**

目前取得了命名实体识别最好的结果。

是在其训练的类似于transformer的双向模型中加上经典的lstm-crf结构。

**Contextual String Embeddings for Sequence Labeling**

**Semi-Supervised Sequence Modeling with Cross-View Training**

目前Ner中取得第二第四。第三第五是bert large 和bert base。

另外重新看了transformer，GPT， ELMo，BERT论文。

# 其他就是看github中命名实体识别的代码，学习tensorflow.
