2019.11.21

**实验进展**

看了pytorch版的一个BiLSTM+CNN+CRF结构的序列标注模型的代码，主要是了解了CRF在计算损失函数和解码过程中的动态规划算法的区别。

在这个基础上搭建自己模型，进展缓慢。

**论文阅读**

| **任务/子任务** | **AD(aspect detection)** | **AS(aspect sentiment)** | **OD(opinion detection)** | **AC(aspect categorize)** |
| --------------- | ------------------------ | ------------------------ | ------------------------- | ------------------------- |
| **ABSA**        | **Done**                 | *****                    |                           |                           |
| **AOWE**        | **Done**                 |                          | *****                     |                           |
| **E2E-ABSA**    | *****                    | *****                    |                           |                           |
| **ACSA**        |                          | *                        |                           | *                         |

ACSA(aspect  category sentiment analysis)是已经设定好了类别，首先判断类别，其次判断类别的极性。

**Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning**

![image-20191119193150676](/home/chuanzi/.config/Typora/typora-user-images/image-20191119193150676.png)

**Earlier Attention? Aspect-Aware LSTM for Aspect-Based Sentiment Analysis**

problem: aspect-unaware problem.

隐藏状态保存的是整个句子的语义信息，存在多个aspect的情况下，有的aspect的信息可能会被忽略，从而造成错误。

method:　aspect-aware LSTM (AA-LSTM) 

在LSTM中利用aspect信息控制信息流。对于隐藏状态向量，会保存有用信息，剔除无用信息。

原有的方法有三种：有上述说的问题

在嵌入层将向量连接

在最终层考虑aspect

隐藏状态向量考虑位置信息

thinking:考虑了aspect word 信息，可以集成到其他模型。保留了对判断aspect极性有用的信息，应该是保留了opinion word 信息。上一篇论文得到aspect opinion word之间的关系模型。都考虑两者之间的关系，前者应该关注与两者之间的语义关系，后者关注与两者之间的结构关系。

结构图：

![image-20191120171013872](/home/chuanzi/.config/Typora/typora-user-images/image-20191120171013872.png)

![image-20191120172014814](/home/chuanzi/.config/Typora/typora-user-images/image-20191120172014814.png)