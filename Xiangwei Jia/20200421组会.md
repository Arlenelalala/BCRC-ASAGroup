# Improving End-to-End Sequential Recommendations with Intent-aware Diversification

![1587450565449](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587450565449.png)

---

通过对用户顺序行为建模来捕捉用户动态意图的顺序推荐可以向用户推荐非常准确的产品。尽管推荐多样性是评价推荐性能的一个重要标准，但以往的研究大多集中在优化推荐精度上，往往忽略了推荐的多样性。因为它们假设用户意图是静态的，并且依赖于对推荐列表的后处理来促进多样性。我们通过提出一个端到端的新模型，称为意图感知的多样化顺序推荐(IDSR)，来考虑推荐的准确性和多样性。

具体来说，我们将**隐式意图挖掘 （IIM） 模块**引入 SR 中，以捕获用户行为序列中反映的不同用户意图。

然后，我们设计了一个**意图感知多样性促进 （IDP） 损失**，以监督 IIM 模块的学习，并强制模型在训练期间考虑推荐的多样性。

对两个基准数据集的广泛实验表明，IDSR 在推荐多样性方面明显优于最先进的方法，同时具有可比较性或卓越的推荐准确性。

---

在传统的推荐（Wu等人，2019年）和网络搜索（Abid等人，2016年）中，对多样化进行了研究。目前的多元化推荐方法主要集中在如何根据一定的多元化度量和一般推荐模型对项目进行重新排序，但这两种方法并不适用于SRs，原因有二：

第一，有些方法假设用户意图是静态的，要求用户意图是事先准备好的，即在大多数SR场景中不现实

第二，他们大多很注重后处理范式，在两个独立的步骤中实现推荐的准确性和多样性，

即1）对项目打分，并生成具有推荐模型的候选项目集;；

（2）根据项目分数和一些隐式/显式多样性指标选择不同的推荐列表

由于推荐模型在学习过程中不了解多样性，难以为不同的复用模型设计理想的多样性策略，这些方法通常较差，远远不能令人满意。 

----

为了解决上述问题，我们同时考虑了推荐的准确性和多样性，并提出了端到端神经模型，提出了一种面向SRs的端到端神经模型，即意图感知的多样化序列推荐（IDSR）。 

通常，IDSR 使用隐式意向挖掘 （IIM） 模块来自动捕获用户行为序列中反映的多个潜在用户意图，并直接生成准确和多样化的推荐列表（w.r.t 潜在用户意图）。为了监督 IIM 模块的学习，并强制模型在培训期间将建议多样性纳入考虑范围，我们设计了一种意向感知多样性促进 （IDP） 损失，该损失基于生成的推荐列表来评估推荐的准确性和多样性。

具体地说，

+ 序列编码器首先用于将用户行为编码为表示。
+ 然后，IIM模块使用多个注意挖掘用户意图，每个注意捕获特定的潜在用户意图。
+ 最后，使用意图感知的推荐解码器通过一次选择一个项目来生成推荐列表。

 

特别是在选择下一个项目时，IDSR还将已经选择的项目作为输入，以便跟踪每个用户潜在意图的满意度。

 

在训练过程中，我们设计了IDP损失来指导IDSR学习挖掘和跟踪用户意图，所有参数都是在统一框架下的端到端反向传播训练范式中学习的。

我们在两个基准数据集上进行了大量的实验，结果表明，IDSR在两个公开数据集上的准确度指标（Recall和MRR）和多样性指标（ILD）均优于最新的基线。 

---

贡献可以概括如下：

 • 提出了一种意向感知的多样化顺序建议 （IDSR） 方法，这是第一个考虑 SR 多样化的端到端神经框架。

 • 设计了一个隐式意向挖掘 （IIM） 模块，以自动挖掘用户行为的潜在用户意图，并设计一个意图感知建议解码器，以生成不同的建议列表。

 • 提出 IDP 损失，以更好地监督 IDSR 的建议准确性和多样性。

 • 对两个基准数据集进行了广泛的实验和分析，以验证IDSR 有效性

---

## 框架：

给定用户U和她的/他的行为序列SU={X1，X2，…，XT}（XI是u与之交互的项目），我们的目标是为U提供推荐列表RL，用于预测她/他的下一个交互，其中项目预期是**相关的和多样的**。

与现有的SR方法不同，我们假设每个行为序列背后都有M个**潜在意图**，即A={a1，…，aM}，然后**通过最大化所有意图的满意程度来生成推荐列表RL**。

![1587451176507](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587451176507.png)

> 其中，P(ai | u)表示意图ai对用户u的重要性。
>
> P(RL | ai，u，Su)是RL对ai的满意概率。
>
> 由于搜索空间庞大，很难直接优化P(RL | u，Su)。因此，建议贪婪地生成 RL，即一次选择一个最高分数 S（v） 的项目。 

![1587451326976](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587451326976.png)

> 其中 vt 是在步骤 t 中要选择的item;
>
> V是所有项的集合；Rt-1是直到步骤t-1生成的推荐列表；V\Rt-1保证所选项与步骤t-1中Rt-1中先前生成的建议不同。S（V）返回项V的得分

![1587451731333](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587451731333.png)

> 它是由一个超参数λ平衡的相关性得分和多样性性得分的组合。
>
> P（v | u，Su）是反映u对v的兴趣的相关性得分。
>
> P（ai | u）是u含有意图ai的概率。P（v | ai）是v对ai的满意程度。
>
> W（Rt−1，ai）表示已经生成的推荐列表Rt-1不能满足ai的可能性。

我们提出了一个端到端的IDSR模型，可以直接根据等式3生成一个多样化的推荐列表。

如图2所示，IDSR由三个模块组成：序列编码器、隐式意图挖掘（IIM）模块和意图感知多样性提升（IDP）解码器。

+ 序列编码器将用户的序列行为编码成潜在的表示形式。
+ 然后，利用IIM模块**捕捉用户**在序列行为中**反映的多个潜在意图**。
+ 最后，利用IDP解码器生成推荐列表
+ 我们设计了IDP损失来训练IDSR，该IDSR从**推荐准确性和多样性**两方面评估整个推荐列表。

请注意，IDSR不涉及重新排序，推荐准确性和多样性都是以端到端的方式共同学习的。接下来，我们介绍单独的模块。

### Sequence Encoder

两种常用的序列建模技术是GRU和Transformer，我们在实验中同时使用了这两种技术（见5），发现IDSR在GRU中表现出更好的性能。因此，这里我们**使用GRU来编码Su**。

![1587452390216](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587452390216.png)

> 其中xt表示项xt的嵌入，Wz，Wr，Wh为权参数，σ表示sigmoid函数，编码器的输入为行为序列Su={x1，x2，…，xt}，输出为隐藏表示{h1，h2，…，hT}，其中hi∈R_de，我们将这些表示叠加到矩阵HS∈R_T*de中，我们认为最后一个表示hT是整个序列的综合。因此我们设定了全局偏好Fu=hT。

### IIM Module

IIM模块是对方程3中的P（ai | u）进行直观的评价，**用户的多种意图可以通过顺序行为中的不同交互来反映**。一些交互比其他交互更能代表特定意图，例如，图1中的最后两个行为反映了观看卡通电影的意图。

基于此，**我们将多意图注意机制与每一个注意融合，以捕捉一个特定的意图**。

IIM首先将HS和Fu分别投射到M空间中，并分别与潜在意图相关。然后，并行使用M个attention函数来生成用户的特定于意图的表示形式

![1587452920433](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587452920433.png)

> 其中意图i的投影矩阵，即W Q i∈R d e×d，W K i∈rde×d和WV i∈rde×d是可学习的参数，我们在这项工作中使用了scaled dot-product attention。

之后，每个意图的重要性，即等式3中的P（ai | u），可以通过:

![1587453163944](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453163944.png)

###  IDP decoder

IDP解码器根据IIM模块挖掘的意图生成RL。首先，我们将v与用户u（即等式3中的P（v | u，Su））的相关性得分建模如下：

![1587453308225](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453308225.png)

类似地，我们在方程中模拟了v与意图ai(即P(v | ai))的相关性。如下:

![1587453355303](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453355303.png)

为了跟踪迄今为止已经选择的项目，我们使用另一个GRU将Rt-1={y1，y2，…，y t-1}编码为{hy 1，hy 2，…，hyt-1}。然后通过计算h y t-1和F i u之间的匹配，我们估计Rt-1对每个意图（即等式3中的W（Rt-1，ai））的满意程度：

![1587453505102](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453505102.png)

最后，我们可以计算每个项目（等式3）的得分S（v），选择概率最高的项目，并将其附加到推荐列表中

### IDP Loss

> 因为我们的目标是生成一个既相关又多样的推荐列表，所以我们设计了IDP损失函数来评估整个生成的列表RL:

![1587453627453](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453627453.png)

> 式中，λ是一个权衡参数，与式3中的参数相同，因为它们都控制着精确性和多样化的贡献。当λ增大时，我们更多地考虑了IDP解码器的准确性和IDP Loss。
>
> 给定IDSR RL={y1，y2，…，yN}的输出建议列表和基本真实项y（即，下一个消费项），L RL rel定义如下：

![1587453791317](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587453791317.png)

> 其中II（yi，y t）是一个指标函数，如果yi=yt，则等于1，否则为0。
>
> p t表示在生成推荐列表RL时，第t步的ground-truth项y的概率。
>
> L RL rel鼓励包含项y的正推荐列表，否则惩罚负推荐列表。注意L RL rel还接受通过将损失与位置t加权，将项目y的位置进行排序。

为了促进多样性，受到网络搜索结果多样化的启发，我们定义L RL div为每个意图ai在RL中至少有一个相关项的概率

![1587454170323](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587454170323.png)

式中，P（ai | u）和P（v | aj）分别在式6和式8中定义。

IDSR的所有参数以及项目嵌入都可以在端到端的反向传播训练范式中学习。

### 精确度

首先，我们可以看到IDSR在召回率和MRR方面优于传统方法POP和FPMC以及基于神经的方法GRU4Rec和HRNN。当推荐列表的大小由10变为20时，IDSR相对于最佳基线HRNN的改进有所增加，具体来说，在ML100K上，IDSR相对于召回@10和召回@20的改进分别为4.16%和6.37%；在ML100K上，IDSR相对于MRR@10和MRR@20的改进分别为5.52%和6.72%，与HRNN相比，IDSR在MRR方面的改进要大于召回。在ML1M数据集上，IDSR相对于HRNN在MRR@20上的改进率为5.32%，在Recall@20上的改进率为3.22%。这可能是因为我们的IIM模块可以捕捉用户的多种意图及其在当前偏好中的重要性。因此，在IDP de编码器的第一步中，IDSR可以给相关项提供高概率。

### 多样性

为了回答RQ2，我们在表2中报告了两个数据集的ILD得分。我们可以看到IDSR始终优于所有基线。在ML100K数据集上，IDSR的ILD@10和ILD@20分别比HRNN提高了19.90%和20.29%，在ML1M数据集上提高了57.76%和50.85%。与后处理基线相比，我们的模型在ML100K数据集上的ILD@10和ILD@20分别比最好的基线模型HRNN+MRR高7.39%和7.97%，在ML1M数据集上的ILD@10和ILD@20分别高10.83%和11.81%。通过配对t检验，观察到IDSR相对于最佳性能基线的显著改善。这证明了我们的模型在提高序列推荐的多样性方面比后处理方法更具竞争力。这可能是因为后处理方法（如MMR）的有效性会受到基线模型的影响。当序列推荐基线生成的候选项类型相似时，MMR方法的性能受到一定的限制。

### 不同编码器

就两个数据集上的所有度量而言，IDSR在GRU上显示出比Transformer更好的性能。我们认为，这是因为变压器依靠位置嵌入来捕获顺序信息，这比GRU更不有效，特别是当变压器没有在大规模数据集上进行预训练时。相比之下，GRU的re-current特性是专门为序列建模而设计的，这意味着它需要较少的数据来捕获序列信息。这可以从DSRGRU在ML1M上相对于DSRTrans的改进要小于ML100K上的改进得到证明，例如，在ML100K和ML1M上，召回率@20的改进分别为10.94%和5.69%。

### 权衡参数λ的影响

我们可以看到，当λ从0增加到1时，准确度指标Recall@20和MRR@20通常呈现上升趋势。当λ=0时，IDSR表现出最差的性能。然而，当λ从0变为0.1时，观察到显著的增加。这是因为λ=0意味着我们只考虑不精确的多样性，因此无法很好地训练模型来推荐相关项。IDSR在精度度量方面表现出最佳性能，在ML100K上的λ约为0.5，而在ML1M数据集上的λ约为0.8。
在推荐多样性方面，当λ从0变为0.1，然后从0.4（0.2）变为1时，两个数据集上的ILD@20的IDSR都会增加。IDSR的最佳多样性表现为较小的λ值，即ML100K上的ILD@0.2，ML1M上的ILD@0.4。当λ设置为1时，IDSR的ILD@20显著下降，表明我们不考虑IDP损失的多样化。总而言之，图3表明，当我们同时考虑准确性和多样化时，我们设计的IDP损失可以提高IDSR的性能。

![1587455178821](C:\Users\jiaxi\AppData\Roaming\Typora\typora-user-images\1587455178821.png)

## Conclusion

本文提出了一种改进SRs的IDSR模型。我们设计了IIM模块来捕获用户的多个意图，并设计了IDP解码器来生成包含这些意图的多个推荐列表。我们还设计了一个IDP损失来监督模型在训练过程中同时考虑准确性和多样性。实验结果和深入分析证实了IDSR在两个数据集上的有效性。
对于未来的工作，一方面，我们计划将我们的模型应用到其他推荐场景中，例如共享帐户推荐，其中行为可以来自多个完全不同意图的用户；另一方面，我们希望通过将最近的SR模型中的有用机制整合到IDSR中，来提高推荐的准确性。