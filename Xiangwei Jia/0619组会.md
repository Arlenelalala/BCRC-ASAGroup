0.ml-1m数据集

> 包含1,000,209个匿名评级，约有3,900部电影，由2000年加入MovieLens的6,040名MovieLens用户制作。
>
> 所有评级都包含在“ratings.dat”文件中，格式如下：
>
> UserID :: MovieID :: Rating :: Timestamp  
>
> - UserIDs范围介于1和6040之间 
> - MovieID介于1和3952之间 - 
> - 评级为5 -star scale（仅限全星评级） -
> - 时间戳以秒为单位表示，因为时间（2）返回 - 
> - 每个用户至少有20个评级ratings
>
> 用户信息位于“users.dat”文件中，格式如下：, 用户信息是在文件“users.dat”，是格式如下：
>
> UserID::Gender::Age::Occupation::Zip-code
>
> - 性别由男性的“M”和女性的“F”表示 - 
>
> - 年龄选自以下范围：
>
>   ```
>   	*  1:  "Under 18"
>   	* 18:  "18-24"
>   	* 25:  "25-34"
>   	* 35:  "35-44"
>   	* 45:  "45-49"
>   	* 50:  "50-55"
>   	* 56:  "56+"
>   ```
>
> - 职业是从以下选项中选择：
>
> - ```bash
>       *  0:  "other" or not specified
>   	*  1:  "academic/educator"
>   	*  2:  "artist"
>   	*  3:  "clerical/admin"
>   	*  4:  "college/grad student"
>   	*  5:  "customer service"
>   	*  6:  "doctor/health care"
>   	*  7:  "executive/managerial"
>   	*  8:  "farmer"
>   	*  9:  "homemaker"
>   	* 10:  "K-12 student"
>   	* 11:  "lawyer"
>   	* 12:  "programmer"
>   	* 13:  "retired"
>   	* 14:  "sales/marketing"
>   	* 15:  "scientist"
>   	* 16:  "self-employed"
>   	* 17:  "technician/engineer"
>   	* 18:  "tradesman/craftsman"
>   	* 19:  "unemployed"
>   	* 20:  "writer"
>   ```
>
> 电影信息位于“movies.dat”文件中，格式如下：
>
> MovieID::Title::Genres
>
> - 标题与IMDB提供的标题相同（包括发行年份） - 
>
> - 类型是管道pipe-separated分隔的，可从以下类型中选择：
>
> - ```bash
>   	* Action
>   	* Adventure
>   	* Animation
>   	* Children's
>   	* Comedy
>   	* Crime
>   	* Documentary
>   	* Drama
>   	* Fantasy
>   	* Film-Noir
>   	* Horror
>   	* Musical
>   	* Mystery
>   	* Romance
>   	* Sci-Fi
>   	* Thriller
>   	* War
>   	* Western
>   ```

# 上周工作：

> 推荐系统

## 1. 算法和模型

### 1.1 FM

> 因子分解机

解决问题：

> 1. 离散特征one-hot编码导致样本稀疏
> 2. one-hot导致特征空间十分巨大
> 3. 一般的线性模型：
>
> ![1.png](https://i.loli.net/2019/06/19/5d09d4836e08c82747.png)
>
> 4. 多项式模型组合二阶特征：
>
>    ![2.png](https://i.loli.net/2019/06/19/5d09d4e387cba21634.png)

求解FM:

特征相关参数有$n(n-1)/2$个，因为数据稀疏，满足xi和xj都不是0的情况很少，导致Wij无法训练；

为了求解$W_{ij}$,对每个特征分量$x_i$引入辅助向量$V_i = (V_{i1},V_{i2}....)$,再利用$V_i*V_j^T$对$W_{ij}$求解。

**这边需要注意一点，k理论上讲，越大越能强化拟合的能力，但是实际在运算过程中，一来受限于计算能力，二来受限于数据量，过大的k只会带来过拟合的问题。我实测了40w作用的数据，观察到k值在6-8左右，valid集合数据拟合效果最优，仅供参考**

1. 行向量Vi

   ![3.png](https://i.loli.net/2019/06/19/5d09d811a674882038.png)

2. Wij矩阵变成：n×n

   W_hat = V×VT

3. 求解vi,vj的推导：

   ![](https://upload-images.jianshu.io/upload_images/4155986-6d08a2cdcc6668fb.png)

   4. 使用SGD 求解

      ![](https://upload-images.jianshu.io/upload_images/4155986-b79f3cdc1229ffbb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/389/format/webp)

   5. 代码执行过程：

   ```reStructuredText
   1. 用户ID	电影ID	打分	时间
   2. 输入变换：scipy.sparse的csr.scr_matrix函数，转成矩阵
   3. TF实现  线性回归部分+特征交叉部分
   4. 平方损失函数+L2正则化
   5. 训练
   ```

### 1.2 FFM

在FM模型中，每一个特征会对应一个隐变量，但在FFM模型中，认为应该将特征分为多个field，每个特征对应每个field分别有一个隐变量。

假设样本的 n个特征属于 f个field，那么FFM的二次项有 nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。

![ffm](https://upload-images.jianshu.io/upload_images/4155986-d04fed8047209d53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/764/format/webp)

如果隐向量的长度为 k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn^2)。

损失函数：FFM将问题定义为分类问题，使用的是logistic loss(类别定义为1，-1时的形式)，同时加入了正则项。

![loss](https://upload-images.jianshu.io/upload_images/4155986-c2df975e6e6a7847.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/webp)

### 1.3 DeepFM

解决问题：不再只是用二阶特征组合，使用DNN产生高阶特征组合，FM低阶

![DeepFM](https://upload-images.jianshu.io/upload_images/4155986-cd51e0bd97ab285d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

DeepFM的预测结果：

$y_{hat} = sigmoid(y_{FM} + y_{DNN})$

FM部分：

![](https://upload-images.jianshu.io/upload_images/4155986-d144aba541c68a34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/582/format/webp)

DNN部分：

![img](https://upload-images.jianshu.io/upload_images/4155986-f9af97ad7e0f5b88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/558/format/webp)

嵌入层(embedding layer)的结构如上图所示。当前网络结构有两个有趣的特性，1）尽管不同field的输入长度不同，但是embedding之后向量的长度均为K。2)在FM里得到的隐变量Vik现在作为了嵌入层网络的权重

效果：

![](https://upload-images.jianshu.io/upload_images/4155986-908ee89d46240580.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)



## 2. surprise库（网易云TopN推荐）

> 封装了一些推荐算法：KNN.SVD.NMF等，可以比较容易的用这个来做一个baseline;
>
> 可以实现的相似度：cos,msd,pearson
>
> 评估准则：rmse，mae，fcp

官方有个使用SVD算法在Movielens数据上进行训练的例子，我在github上找了一个网易云音乐的例子，跑了TopK推荐歌单歌曲。

# 后期任务：

> 1. 按路径学习和尝试其他经典的推荐算法
>    1. 路径：[github](https://github.com/Xw-Jia/tensorflow_practice/tree/master/recommendation)
> 2. 阿里的Transformer《Behavior Sequence Transformer for E-commerce Recommendation in Alibaba》

Transformer 的主要优点是，它能更好地捕获句子中单词之间的依赖性，通过 self-attention 机制，直观地说，用户行为序列中 item 之间的“依赖关系”可以通过 Transformer 抽取。因此，我们提出了在淘宝电商推荐中的用户行为序列 Transformer（BST）。离线实验和在线 A/B 测试表明，BST 与现有方法相比有明显优势。

