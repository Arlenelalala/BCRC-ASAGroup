# 论文阅读

* Improving Entity Linking by Modeling Latent Entity Type Information**

  AAAI 2020

  * **Entity Linking**

    Entity Linking是将一段文本$D$中出现的实体$m_i$与 knowledge base 中的实体$e_i$进行对齐。

    这个过程包括2个步骤：

    * 挑选候选实体集合：从KB中挑选$m_i$可能对齐的实体构成候选实体集$C_i= (e_{i1},...,e_{il_i})$
    * **实体消歧**：从$C_i$中挑选出最佳匹配结果

  * Base model——DeepED

    > **Deep Joint Entity Disambiguation with Local Neural Attention（ACL 2017）**
    >
    > DeepED认为在实体消歧的过程中主要关注两种 contextual information：
    >
    > * **local** **information** based on words that occur in a context window around an entity mention 
    >
    > * **global** **information** exploiting document-level coherence of the referenced entities
    >
    > 我们希望$m_i$与$e_i$能实现：local context compatibility and document-level global coherence。
    >
    > 针对这个目标，DeepED构造了如下的scoring function $g$：
    > $$
    > g(e_1,...,e_n|D)=\sum_{i=1}^nΨ(e_i|D)+\sum_{j\neq i}Φ(e_i,e_j|D)
    > $$
    >
    > * Local model
    >
    >   Local score是用于计算候选集entity embedding和$m_i$上下文的word embedding 的相关性程度。
    >
    >   对于文本$D$中的实体$m_i$，我们在文本$D$中将$m_i$周围的K个词抽出来构成local context $c={w_1,...,w_K}$。
    >
    >   我们用候选实体集的entity embedding $X_e$与local context来计算local context score:
    >   $$
    >   Ψ_{long}(e,c)=X_e^TBh(c)
    >   $$
    >   除此之外，还利用Wikipedia统计了$m_i$与$C_i$中的每个候选实体在同一个页面下被同时提及的次数，作为先验概率$\hat { p } (e|m)$。
    >
    >   结合这两个部分，再通过two-layer FFN，得到：
    >
    >   
    >   $$
    >   Ψ(e,m,c)=f(Ψ_{long}(e,c),log\hat { p } (e|m))
    >   $$
    >
    > * Global model
    >
    >   Global score是用于计算两两候选实体embedding的相关性程度：
    >   $$
    >   Φ(e_i,e_j)=\frac{2}{n-1}X_{e_i}^TCX_{e_j}
    >   $$

  * Motivation

    回到本文，作者在通过对DeepED在AIDA-CoNLL数据集上的错误样本分析，发现超过了一半的错误样本是因为type errors——预测的实体$e_i$ type与目标$m_i$的type不一致。

    ![](https://i.imgur.com/uBR4id6.jpg)

    作者认为DeepED的local context model不能够捕捉到这种Type information。原因有二：

    1. context encoder采用了一个词袋模型而忽略了位置的信息。
    2. DeepED是采用word2vec的方式做word embedding，即衡量词w与目标实体e的相关性，这一过程对Type information不敏感。

    本文利用BERT来捕捉这个隐含的Type information。

  * Model

    1. 得到实体包含Type information的表征

       我们在文本中用MASK替代掉$e_{ij}$:
       $$
       c_{ij} =BERT({lctx_{ij},[MASK],rctx_{ij}})
       $$
       我们将这个送入BERT，将对应[MASK]位置的BERT输出作为结果。

       对于每个实体，我们可以选取 N个这样的上下文段落${c_{i1},...c_{iN}}$，我们将所有结果做平均就得到包含Type information的实体表征：
       $$
       B_{e_i}=\frac{1}{N}\sum_j c_{ij}
       $$

    2. BERT-based Entity Similarity

       对于目标实体m及其上下文：
       $$
       c = BERT({lctx,[MASK],rctx})
       $$
       那么我们通过 context representation c 与entity representation $B_e$来计算BERT-based Entity Similarity：
       $$
       Ψ_{BERT(e,c)}=cosine(B_e,c)
       $$
       我们把这个加入到DeepED的Local model中：
       $$
       Ψ(e,m,c)=f(Ψ_{long}(e,c),Ψ_{BERT(e,c)}，log\hat { p } (e|m))
       $$

  * Experiments

    * Results

    ![](https://i.imgur.com/m6G7SHh.jpg)

    ![](https://i.imgur.com/gtVljYt.jpg)

    * Entity Type Prediction

      Do the entity embeddings from BERT better capture latent entity type information than that of DeepED?

      基于entity embedding做了Type prediction任务

      ![](https://i.imgur.com/FElCZTJ.jpg)

    

* **Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation**

  AAAI 2020

  * Motivation

    对于基于embedding的实体对齐任务，实体是相似度通常是由entity embeddings的距离来衡量。

    GNN通过多层聚合邻居节点信息来获得节点embedding。那么现在已有研究证明GNN对于解决同构图的实体对齐问题非常有帮助。

    但是，对于GNN在异构图上的实体对齐还缺少研究。

    ![](https://i.imgur.com/vtMNzem.jpg)

    不同的邻居结构可能会导致GNN对相同的节点得到差异很大的表征结果。

    ![](https://i.imgur.com/9Ox8uAJ.jpg)

    解决这个问题的难点在于：如何减轻不同KGs相应实体的邻居结构的异构性。

    作者发现：

    > The schema heterogeneity of different KGs usually brings about the mixture of direct and distant neighbors of counter-part entities.

    所以作者希望能引入 distant neighbors information来解决GNN用于异构图的问题。

    ![](https://i.imgur.com/XAtqfaS.jpg)

    本文提出了一种利用Multi-hop聚合邻居节点信息获得 entity representations从而进行KG对齐的网络（AliNet）。

  * Model

    ![](https://i.imgur.com/Tmvi2fe.jpg)

    * Gated Multi-hop Neighborhood Aggregation

       One-hop neighbors：
      $$
      h_{i,1}^{(l)}=\sigma (\sum_{j \in N_1(i)\cup{i}}\frac{1}{c_i}W^lh^{(l-1)}_j)
      $$
      Two_hop neighbors（GAT）：
      $$
      h_{i,2}^{(l)}=\sigma (\sum_{j \in N_2(i)\cup{i}}a_{ij}^l W^l_2h^{(l-1)}_j)
      $$
      用类似Gate的方式：
      $$
      h(l) = g(h^{l}_{i,2}) · h^l_{i,1} + (1 − g(h^{l}_{i,2}) ) ·  h^l_{i,2}
      $$

      $$
      g(h^{l}_{i,2})=\sigma(Mh^{l}_{i,2}+b)
      $$

    * Attention for Distant Neighborhood（$a_{ij}^l$）

      考虑到不是所有的二阶邻居节点对于中心节点都是有意义的，所以在Two_hop neighbors中我们用了Attention的方式来挑选有用的二阶邻居节点。

      与GAT不同，考虑到中心节点与二阶邻居节点在实体图上的含义往往差异很大，我们采用了对中心节点与二阶邻居节点采用了不同的线性变换：
      $$
      c_{ij}^l = LeaklyReLU[(M_1^lh_i^l)^⊤(M_2^lh_j^l))]
      $$

      $$
      a_{ij}^l=softmax_j(c_{ij}^l)
      $$

    * Loss
      $$
      L = L_1+aL_2
      $$
      Loss包括两个部分：

      1. Contrastive Alignment Loss

         这个loss就是希望相同的实体有相同的表示，不同的实体有不同的表示
         $$
         L_1=\sum_{(i,j)\in A^+}||h_i-h_j||+\sum_{(i^′,j^′)\in A^-}a_1[λ-||h_{i^′}-h_{j^′}||]_+
         $$

      2. Relation Semantics Modeling

         ![](https://i.imgur.com/EYaNpAP.jpg)

         我们需要在对齐模型中加入relation loss 的限制。

         relation embeddings：
         $$
         r = \frac{1}{|T_r|}\sum_{(s,o \in T_r)}(h_s-h_o)
         $$
         $T_r$ is the subject-object entity pairs of relation r

         relation loss ：
         $$
         L_2= \sum_{r \in R} \frac{1}{|T_r|}\sum_{(s,o \in T_r)}(h_s-h_o-r)
         $$
         R is the set of the total relations in the two KGs.

  * Experiments

    * Results

      ![](https://i.imgur.com/m7Q7pIm.jpg)

    * 聚合One-hop信息和two-hop信息的方式

      ![](https://i.imgur.com/4MKTMXf.jpg)

    * 不同k-hop结果

      ![](https://i.imgur.com/YrNeBF5.jpg)