## 本周学习内容

### 1. Transformer

实现了google 《Attention is all you need》的Transformer，用来做对联生成。

测试示例如下：

```python
- source: 腾 飞 上 铁 ， 锐 意 改 革 谋 发 展 ， 勇 当 千 里 马 
- got: 奋 进 小 康 ， 精 神 振 奋 创 辉 煌 ， 更 上 一 层 楼

- source: 风 弦 未 拨 心 先 乱 
- got: 月 影 初 临 梦 已 空

- source: 花 梦 粘 于 春 袖 口 
- got: 月 光 照 在 玉 壶 冰

- source: 晋 世 文 章 昌 二 陆 
- got: 唐 朝 诗 赋 耀 千 秋

- source: 一 句 相 思 吟 岁 月 
- got: 三 杯 寂 寞 赋 春 秋

- source: 几 树 梅 花 数 竿 竹 
- got: 一 轮 明 月 一 轮 秋

- source: 未 舍 东 江 开 口 咏 
- got: 不 知 南 海 有 人 观

- source: 彩 屏 如 画 ， 望 秀 美 崤 函 ， 花 团 锦 簇 
- got: 古 镇 似 诗 ， 品 风 流 人 物 ， 韵 雅 诗 情
```

感觉对联任务主观性太强了，不能很好地评价Transformer的性能。所以我还是会再用机器翻译的任务做一下，再跟seq2seq(lstm)结构做对比。

### 2. 推荐系统

上周读了《Efficient Thompson Sampling for Online Matrix-Factorization Recommendation》论文，这周主要是做论文的代码实现。

（1）这篇论文主要是基于**Bayesian Probabilistic Matrix Factorization**，将用户的ratings matrix分解成U, V（ user and item latent features）。

（2）从另一个角度，为了实现在线算法以及解决Exploration&Exploitation问题，论文又采用了解决Multi-Armed Bandit问题的**Thompson Sampling**方法。

（3） 为了计算方便，采用**Rao-Blackwellized particle filter (RBPF) **求后验。

论文的伪代码如下图。

![](https://ws2.sinaimg.cn/large/006tNbRwly1fxnvvpi52lj30zn0u0tet.jpg)

我现在代码框架写出来了，但是伪代码18-19行那里没读明白，就是Rao-Blackwellized particle filter不太明白。



## 下周计划

1. 继续做推荐系统
2. 把文本加上做人物画像的任务
3. 做一些课程上的作业