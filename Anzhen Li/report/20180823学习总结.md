# 20180816学习总结

# 本周工作内容

# 1. Ensemble结果

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fujoq52x0qj30mu0hggnx.jpg)

</n>

# 2. Multi-mask learning

# 1. An overview of multi-task learning 

## 1.1 MULTI-TASK SUPERVISED LEARNING

## 1.1.1 Feature-based MTSL

In this category, all MTL models assume that different tasks share a feature representation, which is induced by the original feature representation.</br>

* Feature transformation approach

  In this approach, the shared feature representation is <u>a linear or nonlinear transformation of the original feature representation</u>.</br>

  * the multi-layer feedforward neural network 

  * the multi-task feature learning

  * the multi-task sparse coding 

    MLFNN: hidden layer contains multiple nonlinear activation units. </br>

    MTFL and MTSC: 
    $$
    { \hat { x }  }_{ j }^{ i }={ U }^{ T }{ X }_{ j }^{ i }\\ { f }_{ i }({ X }_{ j }^{ i })={ ({ a }^{ i }) }^{ T }{ \hat { x }  }_{ j }^{ i }+{ b }_{ i }
    $$
    These two methods aim to learn a <u>linear transformation U</u> instead of the nonlinear transformation in multi-layer feedforward neural networks. </br>

* Feature selection approach

  The feature selection approach aims to select a subset of original features as the shared feature representation for different tasks.

  * based on the regularization on W 

  * based on sparse probabilistic priors on W

* Deep-learning approach

   The deep-learning approach involves neural networks with tens of or even hundreds of hidden layers. </br>

   Most deep-learning models in this category treat the output of one hidden layer as the shared feature representation. </br>

   Unlike these deep models, <u>the cross-stitch network</u> proposed in **combines** the hidden feature representations of two tasks to construct more powerful hidden feature representations.  </br>

$$
  \begin{pmatrix} \tilde { x } _{ i,j }^{ A } \\ \tilde { x } _{ i,j }^{ B } \end{pmatrix}=\begin{pmatrix} { a }_{ 11 } & { a }_{ 12 } \\ { a }_{ 21 } & { a }_{ 22 } \end{pmatrix}\begin{pmatrix} { x }_{ i,j }^{ A } \\ { x }_{ i,j }^{ B } \end{pmatrix}
$$


## 1.1.2 Parameter-based MTSL

Parameter-based MTSL uses model parameters to relate the learning of different tasks. </br>

* Low-rank approach 

  低秩矩阵

* The task-clustering approach

  Divide tasks into several clusters and all the tasks in a cluster are assumed to share identical or
  similar model parameters.

* The task-relation learning approach 

  The task-relation learning approach directly learns the pairwise task relations from data. 

* The dirty approach

  The dirty approach assumes the decomposition of the parameter matrix W into two component matrices, each of which is regularized by a type of the sparsity.

* The multi-level approach

  The multi-level approach decomposes the parameter matrix into more than 2 component ma-trices to model complex relations among all the tasks


## 1.1.3 Instance-based MTSL

 	It first estimates the ratio between probabilities that each instance is from its own task and from a mixture of all the tasks.  After determining ratios via softmax functions, this method uses ratios to determine the instance weights and then learns model parameters.</br>

## 1.1.4 Conclusions

Feature-based MTSL can learn a common feature representation for different tasks and it is more suitable for applications whose original feature representation is not so informative and discrim- inative, e.g. in computer vision, natural language processing and speech. However, feature-based MTSL can <u>easily be affected by outlier tasks that are unrelated to other tasks</u>, <u>since it is difficult to learn a common feature representation for outlier tasks that are unrelated to each other.</u> 

Given a good feature representation, <u>parameter-based MTSL can learn more accurate model parameters</u> and it is more robust to outlier tasks via a robust representation of model parameters. Hence feature- based MTSL is complemental to parameter-based MTSL. 

Instance-based MTSL, which is currently being explored, seems parallel to the other two categories. 

In summary, the MTSL setting is the most important one in the research of MTL since it sets the stage for research in other settings. Among the existing research efforts in MTL, about 90% of works study the MTSL setting, while in the MTSL setting, <u>the feature-based and parameter-based MTSL</u> attract most attention from the community. 

</n>

# 2. An Overview of Multi-Task Learning in Deep Neural Networks

## 2.1 Introduce

* By <u>sharing representations</u> between related tasks, we can enable our model to generalize better on our original task. This approach is called Multi-Task Learning (MTL).

* MTL comes in many guises: <u>joint learning, learning to learn, and learning with auxiliary tasks</u> are only some names that have been used to refer to it. 
* Generally, as soon as you find yourself <u>optimizing more than one loss function,</u> you are effectively doing multi-task learning (in contrast to single-task learning).Even if you are only optimizing one loss as is the typical case, chances are there is an auxiliary task that will help you improve upon your main task. 

* **The goal of MTL：MTL <u>improves generalization</u> by leveraging the domain-specific information contained in the training signals of related tasks.**

## 2.2 Motivation

* A form of inductive transfer.

  * Inductive transfer can help improve a model by introducing an <u>inductive bias</u>, which causes a model to <u>prefer some hypotheses</u> over others.

  * In the case of MTL, the inductive bias is provided <u>by the auxiliary tasks</u>, which cause the
    model to prefer hypotheses that explain more than one task.

## 2.3 Two MTL methods for Deep Learning

In the context of Deep Learning, multi-task learning is typically done with either hard or soft parameter sharing of hidden layers.

* Hard parameter sharing

  * It is generally applied by <u>sharing the hidden layers</u> between all tasks, while keeping several task-specific output layers.

  * Hard parameter sharing greatly reduces the risk of overfitting. 

    The more tasks we are learning simultaneously, the more our model has to find a representation that captures all of the tasks and the less is our chance of overfitting on our original task.

  ![](https://ws1.sinaimg.cn/large/006tNbRwgy1fuh8wnxbu5j31860n20wf.jpg)

* Soft parameter sharing

  * Each task has its own model with its own parameters.

  * The distance between the parameters of the model is then <u>regularized</u> in order to encourage the parameters to be similar.

    对多个模型参数之间的距离进行正则化（结构风险最小化的过程），使得参数相似。

  ![](https://ws4.sinaimg.cn/large/006tNbRwgy1fuh8nuefy1j317o0jkdiv.jpg)

## 2.4 Mechanisms

* Implicit data augmentation

* Attention focusing

  If a task is very noisy or data is limited and high-dimensional, it can be difficult for a model to
  differentiate between relevant and irrelevant features. MTL can help the model focus its attention on those features that actually matter as other tasks will provide additional evidence for the relevance or irrelevance of those features.</br>

  对于单一的model，有时很难区别相关/无关特征，MTL通过多个任务提供额外的信息来帮助model确认哪些特征是task相关特征。

* Eavesdropping

  Some features G are easy to learn for some task B, while being difficult to learn for another
  task A. Through MTL, we can allow the model to eavesdrop, i.e. learn G through task B. </br>

  某些特征通过B任务很好学习，而A任务很难学习。

* Representation bias

* Regularization

   It reduces the risk of overfitting as well as the Rademacher complexity of the model, i.e. its ability to fit random noise.

## 2.5 MTL in non-neural models

### 2.5.1 Enforcing sparsity across tasks through norm regularization


$$
A\quad =\quad \begin{bmatrix} { a }_{ 1,1 } & { a }_{ 1,2 } & ... & { a }_{ 1,t } \\ { a }_{ 2,1 } & { a }_{ 2,2 } & ... & { a }_{ 2,t } \\ ... & ... & ... & ... \\ { a }_{ d,1 } & { a }_{ d,2 } & ... & { a }_{ d,t } \end{bmatrix}
$$
The i-th row of A corresponds to the i-th feature of the model for everytask, while the j-th column of A corresponds to the j-th model.   </br>

行代表特征，列代表task </br>

* Many existing methods make some sparsity assumption with regard to the parameters of our models.

   * [Argyriou and Pontil, 2007] assume that <u>all models share a small set of features.</u> In terms of our task parameter matrix A, <u>this means that all but a few rows are 0</u>, which corresponds to only a few features being used across all tasks. In order to enforce this, they generalize the <u>l1 norm</u> to the MTL setting.

* Block-sparse regularization

  For MTL we compute l1 norm over our task parameter matrix A. 

  We first compute an lq norm across each row containing the parameter corresponding to the i-th feature across all tasks,  which yields a vector :
  $$
  b=\begin{bmatrix} { \left\| { a }_{ 1 } \right\|  }_{ q } & ... & { \left\| { a }_{ d } \right\|  }_{ q } \end{bmatrix}
  $$
   We then compute the l1norm of this vector, which forces all but a few entries of b, i.e. rows in A to be 0.

  In general, we refer to these **mixed-norm constraints as l1/lq norms**. They are also known as
  **block-sparse regularization**, as they lead to entire rows of A being set to 0. 

* Optimization

  As much as this block-sparse regularization is intuitively plausible, it is very dependent on the
  extent to <u>which the features are shared across tasks</u>. 

  For this reason, [Jalali et al., 2010] improve upon block-sparse models by proposing a method that
  **combines block-sparse and element-wise sparse regularization.** They decompose the task parametermatrix A into two matrices B and S where A = B + S. B is then enforced to be block-sparse using  ${ l }_{ 1 }/{ l }_{ \infty  }$ regularization, while S is made element-wise sparse using lasso. 

### 2.5.2 Learning task relationships

Rather than sparsity, we would thus like to leverage <u>prior knowledge</u> indicating that some tasks are
related while others are not. In this scenario, <u>a constraint that enforces a clustering of tasks</u> might be more appropriate. 

## 2.6 Recent work on MTL for Deep Learning

* Deep Relationship Networks

  In addition to the structure of shared and task-specific layers,   [Long and Wang, 2015] place <u>matrix priors</u> on the fully connected layers, which allow the model to learn the relationship between tasks,

* Fully-Adaptive Feature Sharing

  Starting at the other extreme, [Lu et al., 2016] propose a <u>bottom-up approach</u> that starts with a thin network and dynamically widens it greedily during training using a criterion that promotes <u>grouping of similar tasks.</u>

* Cross-stitch Networks

  [Misra et al., 2016] start out with two separate model architectures just as in soft parameter sharing.

  They then use what they refer to as cross-stitch units to allow the model to determine in what way the
  task-specific networks leverage the knowledge of the other task by <u>learning a linear combination of</u>
  <u>the output of the previous layers.</u>

  ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fuhelq08cvj30zy0jo787.jpg)

* A Joint Many-Task Model

   a hierarchical architecture 

  ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fuhgehmtovj30wy0nwgr1.jpg)

* Weighting losses with uncertainty

  They adjust each task’s relative weight in the cost function by deriving a multi-task loss function based on maximizing the Gaussian likelihood with task-dependant uncertainty

* Tensor factorisation for MTL

  Use tensor factorisation to split the model parameters into shared and task-specific parameters for every layer.

* **Conclusion**

  * Most approaches in the history of MTL have focused on the scenario where tasks are drawn from the same distribution.  In order to develop robust models for MTL, we thus have to be able to <u>deal with unrelated or only loosely related tasks</u>.

  * Hard parameter sharing quickly breaks down if tasks are not closely related or require reasoning on different levels. Recent approaches have thus looked towards <u>learning what to share</u> and <u>generally outperform hard parameter sharing.</u>
  * Giving our models the capacity to learn a <u>task hierarchy</u> is helpful, particularly in cases that require different granularities.
  * It is helpful to draw on the advances in MTL that we have discussed and <u>enable our model</u>
    <u>to learn how the tasks should interact with each other.</u>

## 2.7  Auxiliary task

In this section, we will look at how we can find a suitable auxiliary task in order to still reap the benefits of multi-task learning.

* Adversarial

  We have access to a task <u>that is opposite of what we want to achieve</u>,  which is beneficial for the main task as it <u>forces the model to learn representations that cannot distinguish between domains.</u>

* Hints

  Predicting the features as an auxiliary task

* Focusing attention

  The auxiliary task can be used to focus attention on parts of the image that a network
  <u>might normally ignore</u>.

* Quantization smoothing

  For many tasks, the training objective is quantized, i.e. <u>while a continuous scale might be more plausible, labels are available as a discrete set.</u>

   Using less quantized auxiliary tasks might help in these cases, as they might be learned more easily due to their objective being smoother.

* Predicting inputs

* Using the future to predict the present

  In many situations, some features only become available after the predictions are supposed to be made. However, it can be used as an auxiliary task to impart additional knowledge to the model during training.

* Representation learning

  The goal of an auxiliary task in MTL is to enable the model to learn representations that are shared or helpful for the main task.

  </n>

#  3. Dynamic Multi-Level Multi-Task Learning for Sentence Simplification

## 3.1 Model

### 3.1.1 Pointer-Copy Baseline Sentence Simplification Model

### 3.1.2 Auxiliary Tasks

* Entailment Generation

  The task of entailment generation is to generate a hypothesis which is entailed by the given input premise.

  **蕴涵**：陈述句子集合**A**语义上蕴涵句子集合**B**。集合**A**蕴涵集合**B**，当且仅当在其中**A**中所有句子都为真的所有模型中，在**B**中的所有句子也是真的。

* Paraphrase Generation 

  Paraphrase generation is the task of generating similar meaning phrases or sentences by reordering and modifying the syntax and/or lexicon.

### 3.1.3 Multi-Task Learning

In this subsection, we discuss our multi-task, multi-level soft sharing strategy with parallel training of
sentence simplification and related auxiliary tasks (entailment and paraphrase generation).

(1) We share the model parameters in <u>a finer-grained scale, i.e. layer-specific sharing</u>, by keeping some of their parameters private, while sharing related representations;

(2) We encourage shared parameters to be close in certain distance metrics with <u>a penalty term</u> instead of hard-parameter-tying. 

* Multi-Level Sharing Mechanism

  ![](https://ws1.sinaimg.cn/large/006tNbRwgy1fujer9d7s6j30rs0n0tcy.jpg)

  Multi-task model with parallel training of three tasks: sentence simplification (primary task), entailment generation (auxiliary task), and paraphrase generation (auxiliary task). </br>

  Different layers in a sequence-to-sequence model (trained on translation) exhibit different functionalities: lower-layers (closer to inputs) of the encoder learn to represent word structure while higher layers (farther from inputs) are more focused on semantics and meanings.</br>

  * <u>Sharing the lower-level lexico-syntactic layers between the paraphrase generation and sentence simplification tasks,</u> since they share more word/phrase and syntactic level paraphrasing knowledge to simplify the smaller, intermediate sentence pieces.
  * <u>Sharing the higher-level layers between the entailment generation and sentence simplification tasks,</u> since they share higher semantic-level language inference skills.

* Soft Sharing

  Minimize the l2 distance between shared parameters as a regularization along with the cross entropy loss.

  ![](https://ws4.sinaimg.cn/large/006tNbRwgy1fujfczhktxj30ls02yjrl.jpg)

### 3.1.4 Dynamic Mixing Ratio Learning

 We importantly replace this manually-tuned and static mixing ratio with a ‘dynamic’ mixing ratio learning approach, where a controller automatically switches between the tasks during training, based on the current state of the multi-task model.

</n>

# 4. A Multi-task Learning Approach for Improving Product Title Compression with User Search Log Data
This paper proposes a novel multi-task learning approach for improving product title compression with
user search log data.</br>

 In particular, <u>a pointer network-based sequence-to-sequence approach</u> is utilized for title compression with an attentive mechanism as an extractive method and an <u>attentive encoder-decoder approach</u> is utilized for generating user search queries. </br>

The <u>encoding parameters</u> (i.e., semantic embedding of original titles) are shared among the two tasks and the attention distributions are jointly optimized.</br>

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fujn59t45vj30m60d2q4w.jpg)

##  4.1 Objective function

![屏幕快照 2018-08-23 下午3.03.04](/Users/liangsong/Desktop/jupyter notebook/屏幕快照 2018-08-23 下午3.03.04.jpg)

## 4.2 Model

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fujngbn37pj310m0kidjv.jpg)

该方法同时进行两个Sequence-to-Sequence学习任务：主任务基于Pointer Network模型实现从原始标题到短标题的抽取式摘要生成，辅任务基于带有注意力机制的encoder-decoder模型实现从原始标题生成对应商品的用户搜索query。

两个任务之间共享编码网络参数，并对两者的对原始标题的注意力分布进行联合优化，使得两个任务对于原始标题中重要信息的关注尽可能一致。

## 4.3 Agreement-based Learning

We constrain these two distributions agree with each other, which means the important words recognized by two separate decoders are accordant.</br>

 We introduce an attention distribution agreement-based loss:</br>

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fujnlvkinrj30ca036wej.jpg)

 We perform max-pooling on them to get two vectors (aT , aQ ∈ RM ) before calculating the agreement-based loss:</br>

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fujnw6pp3dj30cs02c0sr.jpg)

To evaluate the agreement between aT and aQ, we adopt their KL-divergence as our agreement-based loss. </br>

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fujnxbpfdvj309y01yjrc.jpg)

Finally, the loss function of our multi-task framework becomes:</br>

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fujny0thg1j30n202st8v.jpg)

 λ1 and λ2 are hyper-parameters to tune the impacts of the two tasks.</br>

</n>

# 5. Meta Multi-Task Learning for Sequence Modeling 

* Design and learn the semantic composition function while modeling a text sequence 
* Assigning a label seq Y to a text seq X

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fujofowy5qj30wa0didhd.jpg)

* 提出了两个改进的LSTM模型来对具有多个平行子任务的预测任务进行建模。

* 在多个LSTM之间共享隐变量，改进网络中的参数传递模式。