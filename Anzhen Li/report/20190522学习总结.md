# 语料说明

采用的语料是[nlpcc2017](http://tcci.ccf.org.cn/conference/2017/taskdata.php)。它包含有5万条长中文新闻文本，每个新闻文本有多句的生成式摘要。

具体来说，对于5万条新闻文本和5万条新闻文本对应的摘要：

```
新闻文本平均字符个数 1036.46526
新闻文本最大字符个数 40488
新闻文本最小字符个数 101
新闻文本平均句子个数 22.77692
新闻文本最大句子个数 579
新闻文本最小句子个数 1

新闻文本对应的摘要平均字符个数 45.0983
新闻文本对应的摘要最大字符个数 128
新闻文本对应的摘要最小字符个数 21
新闻文本对应的摘要平均句子个数 1.53916
新闻文本对应的摘要最大句子个数 10
新闻文本对应的摘要最小句子个数 1
```



# 任务理解

* 选取oracle

  因为这个摘要任务是要直接面对用户的，所以不能够采取生成式的方法，要用原文抽取句子的方式得到摘要。

  那么现在的数据集里的摘要是生成式的，所以首先我需要根据数据集的摘要，挑选出原文中的候选句子（这个在论文中被称为oracle）。

  我采用的方法是比较一篇文章中，每个句子与原摘要（多句）之间的rouge-2。在选择了已有oracle候选句的基础上，以贪心的方法继续增加oracle候选句，终止条件是摘要句子不超过5个。

  这样选择下来，oracle中句子个数分布为：{1: 24486, 2: 19205, 3: 5016, 4: 600, 5: 40}。有653个文本没有找到对应的oracle。

* 这个任务是否是必须的？

  按照一般的理解，新闻文本应该在前3句就给出了主要信息。那么还有没有必要做这个摘要任务呢？

  下表是统计除去前num位置的oracle后，摘要不为空的语料的个数。

  ```
  num
  1       34012
  3       25850
  5       20880
  7       17423
  9       14689
  11       12495
  13       10781
  15       9300
  17       8068
  19       7022
  ```

  进一步可以统计，对于整个语料，摘要完全由前3句构成的有23497个（占47%）；完全不包含前3句的摘要有14274个（占30%）；在包含有前3句（大于等于1）的情况下，还包含后面位置句子的摘要有11576个（占23%）。

  下图是对于整个语料oracle出现位置的统计。可以看出除了前3句之外，后面的句子也有很高的出场次数。

  ![屏幕快照 2019-05-22 下午3.21.41](https://ws3.sinaimg.cn/large/006tNc79ly1g3a5cx0zq2j30ye0pg75z.jpg)

  从统计结果可知，对于一篇文章，前3句的重要性的确很高，但是后面的句子对于摘要也有补充内容的意义。所以确实可以做一下这个任务，让用户看到的摘要信息更全面丰富。



# 模型

正在尝试的有2个模型，分别是Neural Document Summarization by Jointly Learning to Score and Select Sentences（ACL 2018 ）以及Fine-tune BERT for Extractive Summarization。

这两篇论文在CNN/DailyMail dataset的表现都很好。第一篇（Neusum）应该是不用bert的模型中效果最好的；第二篇（Bertsum）是用了bert的。

![屏幕快照 2019-05-22 下午4.51.59](https://ws1.sinaimg.cn/large/006tNc79ly1g3a710fa67j30t80f0q5c.jpg)

关于第二篇文章，我之前的理解是需要重新训练整个bert，不过看了代码之后并不是如此，还是在bert的基础上fine-tuning的。

不过我也觉得很奇怪，这篇论文修改了Token Embeddings的方式，在每个句子前都加上一个CLS token（原文是每2句前加一个CLS token），用这个CLS token对应的bert top layer隐藏层的输出作为整个句子的表达，然后送入到后面的摘要抽取网络（比如classifier对应的就是一层线性网络）。

那么这样也能直接fine-tuning吗，毕竟训练的时候，并不是每个句子前都是有CLS token的额，那么这样训练出来的语言模型直接用在这篇论文上也ok吗……



这两篇文章之前都是在英文的数据集上用的，现在用在中文的数据集上，都要做修改一下代码。所以这周主要的工作就是改这2个代码以及读懂整个代码……