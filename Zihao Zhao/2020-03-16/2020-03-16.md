# C model

## 1. WaveNet部署完成

- [x] 调整卷积模式，同一IC中直接累加，不同IC累加时使用加法树。
- [x] padding测试完成
- [x] dilation测试完成
- [x] WaveNet部署完成



## 2. 利用TFlite进行量化

后续计划研究tensorflow的量化方法，把WaveNet模型量化成int8后再在C model中运行。

tensorflow量化需要使用tflite，那些wavenet的代码版本都过低，需要在tf1.x或2.x上进行复现。



WaveNet转化为tflite模型，并进行量化。

量化的主要流程如下：

（1）统计出网络某一层的最大值与最小值：

![[公式]](https://www.zhihu.com/equation?tex=x_%7Bfloat%7D%5Cepsilon+%5Bx_%7Bfloat%7D%5E%7Bmax%7D%2Cx_%7Bfloat%7D%5E%7Bmin%7D%5D)

（2）计算scale与zero_point

![[公式]](https://www.zhihu.com/equation?tex=x_%7Bscale%7D%3D%5Cfrac%7Bx_%7Bfloat%7D%5E%7Bmax%7D-x_%7Bfloat%7D%5E%7Bmin%7D%7D%7Bx_%7Bquantized%7D%5E%7Bmax%7D-x_%7Bquantized%7D%5E%7Bmin%7D%7D)

![[公式]](https://www.zhihu.com/equation?tex=x_%7Bzeropoint%7D%3Dx_%7Bquantized%7D%5E%7Bmax%7D-%5Cfrac%7Bx_%7Bfloat%7D%5E%7Bmax%7D%7D%7Bx_%7Bscale%7D%7D)

（3）通过以下公式计算出任意float32量化后的int8结果

![[公式]](https://www.zhihu.com/equation?tex=x_%7Bquantized%7D%3D%7B%5Cfrac%7Bx_%7Bfloat%7D%7D%7Bx_%7Bscale%7D%7D%7D%2Bx_%7Bzeropoint%7D)





其实量化过程很简单，更高精度的向低精度的范围进行映射。

![[公式]](https://www.zhihu.com/equation?tex=x_%7Bint%7D+%3D+round%28scale+%2A+x%29+%2Bbias+%EF%BC%881%EF%BC%89)

![[公式]](https://www.zhihu.com/equation?tex=x_%7BQ%7D%3Dclam%280%2C+255%2C+x_%7Bint%7D%29)

![[公式]](https://www.zhihu.com/equation?tex=clam%28a%2Cb%2Cx%29%3Da%28x%3Ca%29%7C%7Cx%28a%5Cleq+x%5Cleq+b%29%7C%7Cb%28x%3Eb%29)

在量化过程中，又可以分两个部分，一是模型参数weights，模型一般可以直接使用No saturation的方式直接进行量化， ![[公式]](https://www.zhihu.com/equation?tex=scale%3D%7Cmax%7C%2F127) .

另一部分就是计算过程中的值的量化activations，这部分我们就选择Saturate的方法，这种方法就有一个阈值选择的过程。





- **量化操作**

```text
real_value = scale * (quantized_value - zero_point)
```

上述公式为量化的基本公式，我们看看tflite源码中如何计算其参数scale和zero_point。

在tensorflow/lite/kernels/internal/quantization_util.h 中的ChooseQuantizationParams。可以看到scale由(range_max - range_min) /(q_max - q_min) 决定。比如如果原先range为[0,1], 要quant到8bit([0,255]),则scale为1/255.0。

```cpp
const double scale = (rmax - rmin) / (qmax_double - qmin_double);
```

接着，便是去计算zero_point。由于scale已经确定，zero_point 可以由任何(real_value, quant_value）计算。源码中通过min, max之间映射error的较小值来确定zero_point。

```cpp
  // Zero-point computation.
  // First the initial floating-point computation. The zero-point can be
  // determined from solving an affine equation for any known pair
  // (real value, corresponding quantized value).
  // We know two such pairs: (rmin, qmin) and (rmax, qmax).
  // The arithmetic error on the zero point computed from either pair
  // will be roughly machine_epsilon * (sum of absolute values of terms)
  // so we want to use the variant that adds the smaller terms.
  const double zero_point_from_min = qmin_double - rmin / scale;
  const double zero_point_from_max = qmax_double - rmax / scale;
  const double zero_point_from_min_error =
      std::abs(qmin_double) + std::abs(rmin / scale);
  const double zero_point_from_max_error =
      std::abs(qmax_double) + std::abs(rmax / scale);

  const double zero_point_double =
      zero_point_from_min_error < zero_point_from_max_error
          ? zero_point_from_min
          : zero_point_from_max;
```

再把得到的double型的zero_point 取整为integer。至此，我们便可以对任何一个tensor计算其量化参数scale和zero_point了。

```cpp
  // Now we need to nudge the zero point to be an integer
  // (our zero points are integer, and this is motivated by the requirement
  // to be able to represent the real value "0" exactly as a quantized value,
  // which is required in multiple places, for example in Im2col with SAME
  // padding).
  T nudged_zero_point = 0;
  if (zero_point_double < qmin_double) {
    nudged_zero_point = qmin;
  } else if (zero_point_double > qmax_double) {
    nudged_zero_point = qmax;
  } else {
    nudged_zero_point = static_cast<T>(round(zero_point_double));
  }
```

首先要在训练的过程中，计算loss的函数后面要伪量化计算图。注意在官方文档中有写到，不能在训练一开始就进行伪量化，不然会极大影响模型的精度。tf.contrib.quantize.create_training_graph(quant_delay=2000)正确的方式是加载预训练模型，或是将quant_delay的值设置在模型开始收敛的次数之后。



以下是DFP的表示方法，也是scale的形式。

$$ n= (-1)^s * 2^{-fl} * \sum^{B-2}_{i=0} 2^i*x_i$$



## 3. 后续计划

量化先暂时做到这一步，先进一步模拟硬件。

计划这两天先把内部截位的加乘操作的C语言版本完成。

思考老板说的把C model放入tensorflow的可能性





# 小鼠项目

虽然在验证集上精度已经足够，但实际使用发现精度不足，有一种细胞误差12%，另一种细胞误差24%。

目前何苗老师那边在标注更多数据来进行训练。

还提出了些新需求，比如统计脑区占图片总面积的比例，都是些不复杂但琐碎的需求。





# 论文阅读

## Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks

上次开完会后lsw发给我了这篇论文，我感觉DLA硬件基本就是按照这篇论文定义的一些数据格式进行的，比如minifloat和DFP。



## Training deep neural networks with low precision multiplications

这篇论文中也讲到了minifloat和DFP，研究量化误差时读到了这篇。