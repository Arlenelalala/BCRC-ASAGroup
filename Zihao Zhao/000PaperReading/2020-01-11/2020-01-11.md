1. Chen, F., Song, L., Li, H. H., & Chen, Y. (n.d.). ZARA: A novel zero-free dataflow accelerator for generative adversarial networks in 3D ReRAM. *Proceedings - Design Automation Conference*. https://doi.org/10.1145/3316781.3317936

   出自DAC19，这一篇是一个GAN的加速器，它针对transposed convolution的resouce underutilization做了改进。transposed convolution会引入大量的0，而作者提出了一种新的mapper和scheduler避免了这些0造成的资源浪费。

2. 2.Ryu, S., Kim, H., Yi, W., & Kim, J. J. (2019). BitBlade: Area and energy-efficient precision-scalable neural network accelerator with bitwise summation. *Proceedings - Design Automation Conference*, 1–6. https://doi.org/10.1145/3316781.3317784

   也出自DAC19，是提出了一种precision-scalabel的神经网络加速器，我的理解他们的加速器可以通过配置来得到不同的cost与precision的tradeoff。不过具体实现还没有仔细研究

3. **3.**Brasó, G., & Leal-Taixé, L. (2019). Learning a Neural Solver for Multiple Object Tracking. Retrieved from http://arxiv.org/abs/1912.07515

   这一篇是上个月出现的一篇MOT论文，使用了图网络的方式来处理MOT问题，是基于Message Passing Networks（MPNs）做的。是offline方法，不过效果非常好，目前在MOT17排名第一，看格式应该投稿了CVPR2020，作者说论文接收后会放出代码，值得研究研究。

4. Anonymous. (2020). How much Position Information Do Convolutional Neural Networks Encode? *Iclr*, 1–10. Retrieved from https://openreview.net/forum?id=rJeB36NKvB

   这一篇被ICLR接收为Spotlight论文，主要研究了CNN能否编码绝对位置信息，挺有意思的，值得一看。

5. Simonyan, K., Dieleman, S., Senior, A., & Graves, A. (2016). WaveNet. *ArXiv Preprint ArXiv:1609.03499v2*, 1–15. https://doi.org/10.1109/ICASSP.2009.4960364

   因为在做那个加速器项目，好像要部署WaveNet，所以也研究了一下WaveNet的结构。
