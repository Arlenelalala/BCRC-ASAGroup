## Autism Diagnostics 调研



### ASD(Autistic Spectrum Disorder)

ASD自闭症谱系包括以下三种典型疾病:

- Autism 儿童孤独症(自闭症)
- Asperger Syndrome(AS) 阿斯伯格综合征
- PDD-NOS  未分类的广泛性发育障碍

&nbsp

### ASD的核心症状

- Communication and language

  - 重复刻板语言
  - 自言自语
  - 模仿性语言

- Reciprocal social interaction

  - 社交障碍
  - 缺乏眼神接触
  - 动作缺乏相应表情

- Restricted activities

  - 重复性刻板行为

  - 奇特怪异行为

  - 难以接受改变，执着于特定事物

    > 该症患儿对一般儿童所喜爱的玩具和游戏缺乏兴趣，而对一些通常不作为玩具的物品却特别感兴趣，如车轮、瓶盖等圆的可旋转的东西。有些患儿还对塑料瓶、木棍等非生命物体产生依恋行为。患儿行为方式也常常很刻板，如：常用同一种方式做事或玩玩具，要求物品放在固定位置，出门非要走同一条路线，长时间内只吃少数几种食物等。并常会出现刻板重复的动作和奇特怪异的行为，如：重复蹦跳、将手放在眼前凝视、扑动或用脚尖走路等。 

- ***自闭症儿童行动灵敏,和普通儿童没有区别***

&nbsp

### ASD发病年龄

一般发病于3岁前

自闭症儿童在2岁至4岁期间为最佳干预治疗时间



### 传统机器学习用于ASD诊疗



- Screening Tool：ADOS-R,ADI-R,etc.
- software packages :WEKA, R ,and LIBSVM


&nbsp

#### 设计ASD辅助诊疗系统时，有以下几点应注意：

- binary classification or multi-class  (ASD/non-ASD)
  - 判断患病与否,同时判断病情轻重
- Overlapping label  (ok or not)
  - 医学界有很多难以确诊的病例
- Multi-label  (ADHD / ASD)
  - (ADHD中有32%患者同时患有ASD)

&nbsp

### *辅助诊断系统设计可从下面入手*

- **视频理解,识别刻板行为**
- **语音识别,识别重复性语言**
- **眼神跟踪,确认是否有眼神交流**


&nbsp
------

## 相关技术调研

- 脑电识别（EEG）
  - CT/核磁/脑电/抽血均无法确诊ASD,主要用来排除其他精神疾病
  - 有报道EEG可在婴儿几个月大时预测将来是否患病
- 眼神追踪（Eye Tracking）
- 行为识别（Action ）
- 语音识别（Voice）

&nbsp

### 动作识别

> 1.基于骨架识别（Pose Estimation）
>
> 2.直接识别动作

- 应注意儿童骨架识别的特殊性

- 视频中人类动作识别

  > Unsupervised Action Discovery and Localization in Videos
  >
  > Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks
  >
  > Action Recognition by Hierarchical Mid-Level Action Elements
  >
  > Temporal Action Detection With Structured Segment Networks
  >
  > What Actions Are Needed for Understanding Human Actions in Videos

  - 难点：动作类内差异与类间差异
  - 去除背景干扰：深度信息，动态信息

- 动作相似度标注-Action Similarity Labeling

  > Action Similarity Labeling Challenge_TPAMI_2012
  >
  > Learning Spatiotemporal Features with 3D ConvolutionalNetworks

- Action Re-identification，动作再识别

- 运动轨迹标注

- 热力图显示重复运动轨迹（Heatmap）

![9ada7da0cd2e44d98a954627f09dddb2_th](C:\Users\admin\Pictures\9ada7da0cd2e44d98a954627f09dddb2_th.jpg)http://img.mp.itc.cn/upload/20170620/9ada7da0cd2e44d98a954627f09dddb2_th.jpg
&nbsp
### 视线追踪

- 头戴额外装置，类似VR，拍摄眼部细节，或桌上摄像头

  > Real Time Eye Gaze Tracking With 3D Deformable Eye-Face Model
  >
  > Monocular Free-head 3D Gaze Tracking with Deep Learning and Geometry Constraints  
  >
  > Facial Action Unit Event Detection by Cascade of Tasks  

- 视觉注意力计算

  > Video Based Children's Social Behavior Classification in Peer-Play Scenarios

- 异常眼神变化频率
- 头部动作，对外界刺激（呼喊）有无反应，可以使用姿态传感器

&nbsp

### 语音识别

- 相似波形识别
- 可以不用识别准确语言
- 将重复波形信息提取出，医生分析

&nbsp

### Reference

[1]Machine learning in autistic spectrum disorder behavioral research: A review and ways forward 

[2]Early Diagnosis Autism Based on Upper Limb Motor Coordination in High Risk Subjects for Autism

[3]EEG evidence for mirror neuron dysfunction in autism spectrum disorders


&nbsp


# 浏览目标检测经典论文

主要理解论文大致内容，以及改进网络提升性能的思路，暂未详细阅读论文。



使用CNN进行目标检测主要有两种方案。

1. two-stage的方案是先进行region proposal，再对该候选region进行分类，最后一般还要对bbox通过回归的方法进行精修。典型代表是R-CNN系列算法。
2. one-stage的方案即proposal-free，不需要region proposal阶段，直接产生物体类别概率和bbox位置。通过单次检测直接获得最终检测结果，速度更快。典型代表是YOLO、SSD等。



- Two-stage
  - [x] RCNN
  - [ ] SPPNet
  - [x] Fast RCNN
  - [x] Faster RCNN
  - [x] Mask RCNN
- One-stage
  - [x] YOLO v1
  - [ ] YOLO v2
  - [ ] YOLO v3
  - [ ] SSD
  - [ ] DSOD
  - [ ] Retinanet



### RCNN

•2014CVPR

论文思路：

生成约2000个候选bbox（selective search）

-->resize后送入CNN提取特征

-->提取的特征送入classifier进行分类

-->概率最高的bbox吸收多余的bbox（IoU、NMS）

-->回归算法获得更精确的bbox



### Fast RCNN

•2015 ICCV

受SPPNet启发，加入RoI Pooling层

将bbox回归与region分类合并成一个multi-task模型，共享卷积特征，相互促进，Speed↑，Acc↑

完整图片-->CNN提取特征

​                    -->特征图中找出RoI区域-->分类+bbox回归



### Faster RCNN

提出Region Proposal Network(RPN)

​	由CNN来搜索候选bbox

完整图片-->CNN提取特征-->特征图传入RPN得到候选bbox

​	对候选bbox使用分类器-->回归器调整bbox



### Mask RCNN

以往RCNN中的RoI Pooling

  ----  将不同大小的输入映射到固定尺度的特征向量

特征图中对应原图RoI的位置分成n*n(固定尺度)个àmax pooling

（其中RoI直接由原图的RoI resize到feature map上,此步会取整,丢失精度）

改进成RoI Align

①原图RoI->feature map时不再取整

②RoI Pooling在特征图分块时进行双线性差值,不再四舍五入



------



### YOLO v1—You Only Look Once

> Joseph Redmon∗, Santosh Divvala∗y, Ross Girshick{, Ali Farhadi∗y    
>
> University of Washington∗, Allen Institute for AIy, Facebook AI Research{    



​	RCNN系列均需要生成候选框，在候选框上进行分类与回归，但候选框之间有重叠，这会带来很多重复工作。		    	  		

​	YOLO 的核心思想就是利用整张图作为网络的输入，直接在输出层回归 bounding box（边界框） 的位置及其所属的类别。 faster-RCNN 中也直接用整张图作为输入，但是 faster-RCNN 整体还是采用了RCNN de的proposal +classifier 的思想，只不过是将提取 proposal 的步骤放在 CNN 中实现了，而 YOLO 则采用直接回归的思路。 
$$
Pr(Class_i|Object) ∗ Pr(Object) ∗ IOU^{truth}_{pred} = Pr(Class_i) ∗ IOU^{truth}_{pred}
$$
​	在 test 的时候，每个格子预测的 class 信息和 bounding box 预测的 confidence信息相乘，就得到每个 bounding box 的 class-specific confidence score.等式左边第一项就是每个网格预测的类别信息（物体是某一类的概率），第二项为是否有物体的概率，第三项为预测bbox与实际bbox的IoU，第二、三项相当于每个 bbox 预测的 confidence。这个乘积即 encode 了预测的 box 属于某一类的概率，也有该 box 准确度的信息。 

​	YOLO将全图划分为SXS的格子，每个格子负责中心在该格子的目标检测，采用一次性预测所有格子所含目标的bbox、定位置信度以及所有类别概率向量来将问题一次性解决(one-shot) 

​	由于每个格子最多只预测出一个物体，所以当物体占画面比例较小，如图像中包含畜群或鸟群时，每个格子包含多个物体，但却只能检测出其中一个。这是 YOLO 方法的一个缺陷。 

#### 损失函数及其他细节

损失函数包括几个部分，比较复杂，待完全理解网络后再做分析。

细节较多，下一步通过代码进行学习。

> 代码下载：<https://github.com/pjreddie/darknet>  

#### 缺点总结

1. （大小物体处理）一个格子里有多个物体（鸟群等小物体），或两个大物体靠的很近时，识别效果不好。因为每个格子只属于一个class。
2. （定位误差大）由于按小格子的方式进行预测分类，定位分辨率不高，不能实现accurate localization。
3. （泛化能力弱）同一类物体出现不常见的长宽比或其他意外情况时，不容易检出，泛化能力偏弱。







### YOLO v2------YOLO 9000

​	YOLO9000，采用了联合训练的方法，利用了数据量更大的分类数据集来扩充检测数据集。9000意为可检测超过9000类物体。

> We propose a new method to harness the large amount of classification data we already have and use it to expand the scope of current detection systems. Our method uses a hierarchical view of object classification that allows us to combine distinct datasets together.
>
> We also propose a joint training algorithm that allows us to train object detectors on both detection and classification data. Our method leverages labeled detection images to learn to precisely localize objects while it uses classification images to increase its vocabulary and robustness.       

------



# Inception系列总结(提升网络宽度)



![](E:\Inception series\20160904154907381 (1).jpg)



Inception系列均为Google出品

## Inception V1(GoogleNet)

> [v1] Going Deeper with Convolutions, 6.67% test error  <http://arxiv.org/abs/1409.4842>  

​	Inception V1 is called GoogLeNet, a ***22 layers deep network***, the quality of which is assessed in the context of classification and detection.    

​	增加网络深度和宽度的同时减少参数，Inception就是在这样的情况下应运而生。 

![1533211453627](C:\Users\admin\AppData\Local\Temp\1533211453627.png)

![1533211433756](C:\Users\admin\AppData\Local\Temp\1533211433756.png)



#### Exact Structure

```
• An average pooling layer with 5×5 filter size and stride 3, resulting in an 4×4×512 output for the (4a), and 4×4×528 for the (4d) stage.    

• A 1×1 convolution with 128 filters for dimension reduction and rectified linear activation.

• A fully connected layer with 1024 units and rectified linear activation. 

• A dropout layer with 70% ratio of dropped outputs. 

• A linear layer with softmax loss as the classifier (predicting the same 1000 classes as the main classifier, but removed at inference time).    
```

​	第一张图是论文中提出的最原始的版本，所有的卷积核都在上一层的所有输出上来做，那5×5的卷积核所需的计算量就太大了，造成了特征图厚度很大。为了避免这一现象提出的inception具有如下结构，在3x3前，5x5前，max pooling后分别加上了1x1的卷积核起到了降低特征图厚度的作用，也就是Inception v1的网络结构。 



#### Training Methodology

> Our training used asynchronous stochastic gradient descent with 0.9 momentum [17], fixed learning rate schedule (decreasing the learning rate by 4% every 8 epochs). Polyak averaging [13] was used to create the final model used at inference time.    





## Inception V2 V3

> [v2v3] Rethinking the Inception Architecture for Computer Vision, 3.5% test error  <http://arxiv.org/abs/1512.00567>  

减少特征的表征性瓶颈。直观上来说，当卷积不会大幅度改变输入维度时，神经网络可能会执行地更好。过多地减少维度可能会造成信息的损失，这也称为「表征性瓶颈」.



##### General Design Principles

​	we will describe a few design principles based on large-scale experimentation with various architectural choices with convolutional networks.

1. Avoid representational bottlenecks, especially early in the network.
2. Higher dimensional representations are easier to pro-cess locally within a network.
3. Spatial aggregation can be done over lower dimen-sional embeddings without much or any loss in rep-resentational power.
4. Balance the width and depth of the network.

##### Factorization into smaller convolutions

![1533291471074](C:\Users\admin\AppData\Local\Temp\1533291471074.png)

5\*5的卷积核与两个3\*3的卷积核是等效的。

但两个3*3卷积层可以减少参数,(9+9)/25=78%。

![1533292103253](C:\Users\admin\AppData\Local\Temp\1533292103253.png)

单个3\*3卷积核分解为2个3\*1与1\*3卷积核（减少33%参数）。

同理，n\*n可以分解为n\*1与1\*n。

若分解为2个2\*2卷积核，只减少11%参数。



![1533293028213](C:\Users\admin\AppData\Local\Temp\1533293028213.png)

让网络变得更宽，来解决representative bottleneck（表征性瓶颈？）

##### Auxiliary Classifiers

​	让很深的网络能够收敛。把有用的梯度信息传回lower层，可以让这些梯度信息立刻生效，以此促进网络收敛。与过深网络中的梯度消失现象做对抗。（研究ResNet论文，比较其方案区别）

​	Auxiliary Classifiers在训练前期并无效果。在训练后期，存在auxiliary branches的网络会稍微超过普通网络的准确率（reaches a slightly higher plateau）。作者认为辅助分类器的功能是正则化，尤其是它们具备BatchNorm 或 Dropout 操作时。 

##### the grid reduction technique

to avoid introducing the representative bottleneck

![1533302643634](C:\Users\admin\AppData\Local\Temp\1533302643634.png)

左图引入了representative bottleneck，损失了信息，应该采用右图的方式。

## Inception V4

> [v4] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test error  <http://arxiv.org/abs/1602.07261> 

Inception 结合 Residual connection 结构



## ResNet





## DenseNet





## Xception



------





# 一些概念

## SGD（随机梯度下降）

带随机噪声的梯度下降，可以逃离局部最优点。

BGD-->mini_BGD-->SGD







## Batch Normalization

BN就是在神经网络的训练过程中对每层的输入数据加一个标准化处理。 

> [v2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test error  <http://arxiv.org/abs/1502.03167> 
>
> 提出batch normalization
>
> 
>
> YOLO v2 : 使用 Batch Normalization 对网络进行优化，让网络提高了收敛性，同时还消除了对其他形式的正则化（regularization）的依赖。通过对 YOLO 的每一个卷积层增加 Batch Normalization，最终使得 mAP 提高了 2%，同时还使模型正则化。使用 Batch Normalization 可以从模型中去掉 Dropout，而不会产生过拟合。 



We define Internal Covariate Shift as the change in the distribution of network activations due to the change in network parameters during training.



## Bottleneck

为了减少参数

> ResNet:Because of concerns on the train-ing time that we can afford, we modify the building block use a stack of 3 layers instead of 2 (Fig. 5). The three layers as a bottleneck design4. 





## 梯度消失&梯度爆炸

​	网络过深会导致梯度消失。从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。 

​	解决梯度消失&爆炸问题  **Relu**  思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。 但是relu的缺点是1.部分神经元无法激活，如果学习率设置得太高，可能会发现网络中 40% 的神经元都会死掉（在整个训练集中这些神经元都不会被激活） 。设置小学习率可改善这一现象。2.不是0中心，（~~收敛速度会慢~~，虽然不是0中心，但速度很快。2的坏处？）。



## Receptive Field(感受野)

> 卷积神经网络中的感受野计算（译）https://zhuanlan.zhihu.com/p/26663577
>
> A guide to receptive field arithmetic for Convolutional Neural Networks https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807



在CNN中，**第n层**特征图中一个像素，对应**第1层**（输入图像）的像素数，即为该层的Receptive Field，简称RF。 



![img](https://pic4.zhimg.com/80/v2-d7da0044ca0e6e93fcee492c3a0b3b49_hd.jpg) 



​	感受野表示输入空间中一个特定CNN特征的范围区域（*The receptive field is defined as the region in the input space that a particular CNN’s feature is looking at）*。一个特征的感受野可以采用区域的中心位置和特征大小进行描述。图中展示了一些感受野的例子，采用核大小（kernel size）k=3*3，填充大小（padding size）p=1*1，步长（stride）s=2*2的卷积核C对5*5大小的输入图进行卷积操作，将输出3*3大小的特征图（绿色图）。对3*3大小的特征图进行相同的卷积操作，将输出2*2的特征图（橙色）。 

​	右边一列展示了一种固定大小的CNN特征图可视化方式，通过保持所有特征图大小和输入图大小相同来解决计算特征的位置（感受野的中心位置）和区域大小（感受野尺寸） 的问题，接下来每个特征位于其感受野的中心。由于特征图中所有特征的感受野尺寸相同，我们就可以非常方便画出特征对应的包围盒（bounding box）来表示感受野的大小。因为特征图大小和输入图像相同，所以我们无需将包围盒映射到输入层。 

​	神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着他可能蕴含更为全局、语义层次更高的特征；而值越小则表示其所包含的特征越趋向于局部和细节。因此感受野的值可以大致用来判断每一层的抽象层次。 







### CNN Visualization（可视化）

> Visualizing and Understanding Convolutional Network  ECCV2014

Deconvolution

unpooling
