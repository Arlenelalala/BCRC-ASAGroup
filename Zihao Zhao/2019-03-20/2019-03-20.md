本周在进行多目标跟踪的实验，计划先从实现RPN思路开始。

# 1.基础

大概两天的时间，补pytorch的基础，看了两本Pytorch的书。

> 深度学习框架PyTorch：入门与实践，陈云
>
> 深度学习之Pytorch，廖星宇

与此同时完成了线性回归器的训练，相当于只有一层全连接层的神经网络。

# 2.实践

之后开始编程实践，编程学习路线如下：

线性回归器→LeNet手写数字识别→VGG19

以上三步，纯手写全部代码，已经全部搞定。

# 3.动手

然后准备开始编写自己的网络。

目前花费时间比较多的部分有：Dateloader部分，Loss部分。



目前的网络结构很简单，模仿Faster RCNN，使用VGG16进行特征提取，去掉最后一层池化。特征提取之后采用全卷积的方式，加一个3x3层，和一个1*1层。

输入900x512x3的图像，输出为58x34x512通过1*1卷积，最终变成58x34x1。

目前思路是把输出当做响应图，直接与标签进行比对，像素级求MSELoss。

标签是根据boundingbox生成的58x34标注图。



自己的网络第一版已经跑起来了，从开始训练到最后收敛，loss只能下降一半，看上去效果并不好，但是是意料之中，还有很多细节没有考虑，接下来继续细化思路进行调整。



##### 目前思考的问题：

​	1.loss的量级与网络输出的量级

​	2.标注图是否合理



目前大方向依旧是做出统一的多目标跟踪框架。等做出baseline之后再考虑加入Re-ID，场景建模等部件。
