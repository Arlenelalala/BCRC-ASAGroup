# 1.CUDA编程

![](./gpu.png)

看书《CUDA并行程序设计：GPU编程指南》，现在看到第三章，刚开始编程实践。上图为经典GPU结构图，GPU由很多个SM（Streaming Multiprocessor）构成，而每一个SM包含一组SP（CUDA核）。1080Ti里有28个SM，每个SM有128个CUDA核，总共有3584个CUDA核。

而具体到软件层面，在CUDA 架构下，GPU芯片执行时的最小单位是线程（thread）。若干个thread可以组成一个线程块（block）。一个block中的thread能存取同一块共享内存，可以快速进行同步和通信操作。每一个block 所能包含的thread 数目是有限的。执行相同程序的block，可以组成grid。在1080Ti里每一个block最多包含1024个thread，而每一个block共享内存大小为48 KB。

CUDA的设备在实际执行过程中，会以block为单位。把一个个block分配给SM进行运算；而block中的thread又会以warp（线程束）为单位，对thread进行分组计算。目前CUDA的warp大小都是32，也就是说32个thread会被组成一个warp来一起执行。同一个warp中的thread执行的指令是相同的，只是处理的数据不同。



# 2.研究DAC2019论文

实际可以借鉴的论文：

**Lightweight Quantized Deep Neural Networks for Fast and Accurate Inference**

**Accuracy vs. Efficiency: Achieving Both through FPGA-Implementation Aware Neural Architecture Search**

**eSLAM: An Energy-Efficient Accelerator for Real-Time ORB-SLAM on FPGA Platform**



感觉比较适合我们发的有以下一些topics。

DES3. Approximate Computing for AI/ML

- ***DES3.1 Quantization, Pruning and Model Compression***
- **DES3.2 Approximate and Stochastic hardware for AI/ML**
- **DES3.3 Cross-layer approximations and accuracy tradeoffs in AI/ML**

DES4. AI/ML System Design 

- *DES4.1 HW and system architectures for neural network training and inference*
- *DES4.2 Architectures for emerging AI/ML algorithms (beyond neural networks)*
- *DES4.3 AI/ML Architectures with Beyond-CMOS technologies*
- ***DES4.4 Software frameworks and libraries for AI/ML***
- ***DES4.5 Automating AI/ML system design (AutoML)***

ESS1. Embedded Software

- *ESS1.1 Embedded software verification methodologies*
- *ESS1.2 Embedded operating systems, middleware, runtime support, resource management, and virtual machines*
- ***ESS1.3 Software techniques for multicores, GPUs, and multithreaded embedded architectures***
- ***ESS1.4 Compilation strategies, code transformation and parallelization techniques for embedded systems***
- ***ESS1.5 Domain-specific embedded libraries (e.g., for machine learning)***
- *ESS1.6 Embedded Software Development Case Studies (e.g., ANDROID development, ARM-based systems, etc.)*
- *ESS1.7 Operating Systems and Middleware*
- ***ESS1.8 Software Design and Analysis***

SEC3. Embedded and Cross-Layer Security

- *SEC3.1 Embedded software and system-level techniques for security*
- *SEC3.2 Architectural support for software and embedded systems security*
- *SEC3.3 Cyber-physical systems and IoT security*
- *SEC3.4 Embedded security: metrics, models, verification and validation*
- ***SEC3.5 Machine learning for cyber defense***
- ***SEC3.6 Security vulnerabilities in artificial intelligence***

# 3.VOTtoolkit安装

暂未成功。

# 4.读论文ATOM与DiMP

## DiMP. Learning Discriminative Model Prediction for Tracking 

![](./dimp_overview.png)

DiMP is an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. It is based on a target model  prediction network, which is derived from a discriminative learning loss by applying an iterative optimization procedure. The model prediction network employs a steepest descent based methodology that computes an optimal step length in each iteration to provide fast convergence. The model predictor also includes an initializer network that efficiently provides an initial estimate of the model weights.



## ATOM: Accurate Tracking by Overlap Maximization

![](./atom_overview.png)

ATOM is based on (i) a **target estimation** module that is trained offline, and (ii) **target classification** module that is trained online. The target estimation module is trained to predict the intersection-over-union (IoU) overlap between the target and a bounding box estimate. The target classification module is learned online using dedicated optimization techniques to discriminate between the target object and background.

