# 画钟

## 问题重述

输入一张二值化后的病人画的钟表的图片（除了钟表之外没有任何其他的噪声）（**比较强的限制，可以通过前期预处理达到这个效果**），输出评分。

deadline突然变成七天后。

![](/Users/wangchengbin/Desktop/组会0905/clock-processed.jpg)

### 评分标准

n1: 要求包含1-12的数字；多或少数字错误；数字位置，顺序不考虑；

n2: 要求数字顺序必须正确；数字位置，是否为1-12不考虑；

n3: 数字平均分布；必须包含1-12,且1、2、3，4、5、6，7、8、9，10、11、12分别处于右上角，右下角，左下角，左上角；多或少数字错误；各区域内部数字顺序不考虑；

h1: 有两个指针；是否有箭头，两个指针长短不考虑；

h2: 有一个指针指向数字4；数字位置，是否为短指针不考虑；

h3: 有一个指针指向数字8；数字位置，是否为短指针不考虑；

h4: 有一长一短两个指针，指针是否指向4、8，指针的位置不考虑。

## 难点

### 抓取图像中的的数字部分

该任务可抽象为监督学习任务和伪无监督学习任务。首先，该任务严重缺乏数据：目前只有像MNIST的数据集那样的**classification**数据集，没有像imagenet那样的图像分割的数据集，导致不好搞ground truth。

#### 监督学习任务

用YOLO之类的图像分割方法，需要重新做一个数据集。首先，确定将来的输入图像尽可能resize在(300,300)这个尺寸，然后，做一个(300,300)的纯黑二值化图像，将其中随机(28,28)的部位替换成MNIST中的随机图像，并做出这个图像的json描述文件（图像名，识别到的数字，bbox的5个参数）。

没有bbox是没法定义损失函数的。这是YOLO等图像分割网络的一个特点。或者可以重新定义一下损失函数，但是我没有想到什么好的方法。

YOLO的损失函数如下：

![](/Users/wangchengbin/Desktop/组会0905/YOLO-loss.png)

但是这个方法可能会有一些不好的地方：

- 一张图中只有一个数字（倒是可以生成多个，但是多少个呢，这个超参数还是要仔细调整的）
- 背景单调无噪声（倒不是不能生成噪声，但是像椒盐噪声之类的噪声品种生成谁比较好这个我目前拿不准）

以上两点可能会使得整个网络泛化性能极差。所以我没有尝试做训练集之后进行训练（训练了得到不好的结果，是调参数还是丰富数据集）。

其实最好的样本就是直接在画钟的图像上人工标注，但是1图片数量少2图片中的数字质量堪忧，所以我觉得这条路行不通。而且时间不允许。。。

#### 伪无监督学习任务

先画框，再检测。主要的检测方式是基于LeNet的简单架构，inference时间应该会比较短，但是仅仅是基于**一次检测**的时间。可行区域如果太多的话，整个执行时间会十分地长。

举个例子，若是使用金字塔式的特征提取手段（从haarcascade加adaboost的方法中提取到的灵感），具体参数假设如下：

- 图片大小：(300,300)
- MNIST的数字图片大小：(29,29)

使用金字塔式抽取特征的方法的话，假设置信数字区域从(25,25)到(35,35)的话，将会产生：

- 每张图片需要调用约680,000次单一图像的inference

这样很蠢。但是要是没有更加精确的方法的话，就只能使用这种方法了。

我有几个不成熟的想法，主要想解决**如何减少可行区域（如何使尝试的区域尽可能少，不漏掉每一个数字）**：

- 自编码器，中间输出的编码是**可能的数字位置的中心坐标**，然后在从这个中心坐标开始往外扩张，可以显著降低计算次数。但是：如何让编解码器中的码是我们想要的那种数据类型？
- 注意力机制，返回可能的数字中心位置。我觉得在图像中的注意力机制是可行的，但是我现在只发现了基于**文字描述**找图像中值得集中注意力的论文，这样的话，若是固定文字描述（比如数字），应该是可以降低计算量的。到那时我觉得使用文字当作中间桥梁这个主意很蠢，一定有更好的无监督解决方案。什么是这张图片中值得集中注意的地方。

### 评判规则

目前正在打桩，估计这个任务得在实践中接着调整，不好的例子足够多，规则就会出现足够大的漏洞。而且，病人的思维模式跟医生的思维模式不同，医生画的钟的模式跟病人画的钟的模式是不同的。这一点需要慎重考虑。

所以我想在每次评分之后，输出：这个病人为什么会得这个分数，并且若是程序不足以判定的话，说清楚为什么程序不足以判定这个问题，将程序作为医生的辅助而不是取代医生的程序，我觉得这样的设计应该是蛮合适的。

我现在做的这个程序，我觉得应该只是一个以“辅助医生做诊断”为借口的搜集数据的程序。。。没见到过足够多的数据我是真的写不完整规则。

#### 可能会出现的反例

**我需要看一下二十几张病人画的钟，看一下可能会出现的问题。**

若是有重复出现的数字应该如何处理？

若是数字超出边界应该如何处理？

- 在评分标准里面，没有对边框的要求，所以这里的评价标准就是：数字中是否有与边框相交的地方，或估计一个大体的圆形边框，查看这个圆形边框切下来了多少bbox。

## 算法流程

正在打桩。思路还是不明确。

# 步态

## 成果

### 腾讯AI&华山医院

[**帕金森病运动功能智能评估系统**](https://mp.weixin.qq.com/s/y5SFHPjGtTAEHj27ajO-BQ)

顺带说一下，腾讯医疗AI的官网上并没有发现关于这个项目的介绍，只有新闻中提及了，说明这个项目还没有成熟到可以挂在官网上，所以我推测这个项目并没有做完。

没有找到相关论文。

> 腾讯方面则分享称，此次的帕金森病运动功能智能评估系统主要有三大技术特点：动态特征捕捉（通过姿态卷积预测全身关节位置），时序分析技术（通过时序卷积保证全身关节在时间维度上的连贯性），以及动态分析技术（利用记忆网络和人体动力学模型输出可靠的运动指标）。
>
> 原理上，基于无可穿戴传感器的运动视频分析技术，针对帕金森病人的运动视频自动实现UPDRS（国际普遍采用的帕金森氏病评分量表）评分。 
>
> 此技术是一项运动障碍性疾病的通用视频分析技术，可以拓展到国际上更加通用的MDS-UPDRS评分体系，除了用于帕金森病的辅助诊断，还可以用于其他运动障碍性疾病。

在找所谓的时序卷积的时候，发现了一篇蛮有意思的论文：[Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition](https://arxiv.org/pdf/1801.07455.pdf)

我们应该怎么分析视频流中的动作呢？这个问题的答案可能是：

- 使用3D卷积
- 使用LSTM（但是可能会丢失顺序信息）

这篇论文提出了另外一种方法：从将骨架序列理解为一帧帧的骨架演进为将整个视频理解为一个整体的时空图。

用图来表示时间的流逝。。。

这篇论文真的挺有意思的。。。

骨骼节点带着真哥哥图跑，会如何。。。