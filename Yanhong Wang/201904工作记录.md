<<<<<<< HEAD
[TOC]

[第三周](#第三周)

[第四周](#第四周)

# 分周计划

## 20190404-20190410

### 周总结

* 步态算法监视程序重构，逻辑线更清楚
* 模型压缩相关知识，并参与比赛
* 出差布点
* 课程报告相关准备

## 20190411-20190417

### 周计划

- 模型压缩
- 协助完成语音收集
- 按照计划出差布点
- 看论文
- 课程报告

### 周总结

* 模型压缩看了一些，但是没有看很多，半篇论文（deep compression），研究了几个代码
* 语音收集完成一个人，主动来找的人
* 做实验室网页：<http://webplus.fudan.edu.cn/_s342/main.psp>
* 做课程报告：英语&计算机体系结构
* 总结：这周较多时间花在了实验室网页制作和课程上，关于deep compression的进度较慢，论文和代码方面花费精力较少。下周应作出相应调整

## <span id="第三周"> 20190418-20190424 </span>

### 周计划

* 论文：至少两篇（拿人头保证）
* 调研：完成模型压缩调研报告和三维恢复方向调研报告
* 实验室网页优化

### 周总结

* 实验室网页优化（完成，偷了研究生招生网站的模板，看起来正规了很多，好开心）
* 出差两天
* 语音数据采集完成
* 调研报告：
  * 发现要看的论文好多好多，未完成

* 论文阅读

| 论文分类                   | 论文名称                                                     | 阅读状态 | 时间 |
| -------------------------- | ------------------------------------------------------------ | -------- | ---- |
| 模型压缩                   | Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | 完成     | 本周 |
| 模型压缩综述               | A Survey of Model Compression and Acceleration for Deep Neural Networks | 一半     | 本周 |
| 轻量级网络                 | Light-Head R-CNN: In Defense of Two-Stage Object Detector    | 完成     | 本周 |
| 轻量级网络                 | ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices | 一半     | 本周 |
| 其他一些轻量级网络粗略阅读 | ![1556157752122](201904工作记录.assets/1556157752122.png)    | 粗略了解 | 本周 |

* 代码工作：

| 参考                                                       | 备注                                                         | 代码实现结果                       |
| ---------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------- |
| Learning Correspondence from the Cycle-consistency of Time | 因为这篇论文用仿照cycle gan的方式训练网络，不需要标签，得到了一个用于检测，分割，关键点检测的网络，所以想用我们的数据集测试一下是否可行 | 失败，搞了一天，环境配置失败，放弃 |

## 20190425-20190501

### 周计划

- 多看模型压缩的论文并作出总结

  > 本周感兴趣论文
  >
  > 模型压缩方面两篇综述
  >
  > ![1556158509195](201904工作记录.assets/1556158509195.png)
  >
  > 轻量级网络，据说打败yolov3
  >
  > ![1556158770045](201904工作记录.assets/1556158770045.png)
  >
  > 上周复现失败的论文，想看看到底有没有价值：
  >
  > ![1556158748848](201904工作记录.assets/1556158748848.png)

### 周总结

* 论文阅读

| 论文名称                                                     | 阅读笔记                  |
| ------------------------------------------------------------ | ------------------------- |
| Recent Advances in Efficient Computation of Deep CNN，2018CVPR, 程建，中科院自动化模式识别所 | [综述阅读](#综述阅读笔记) |

### 详细

#### 1.<span id="综述阅读">Recent Advances in Efficient Computation of Deep CNN，2018CVPR</span>

* **Motivation**

  >神经网络的计算复杂度，资源消耗逐年激增，那应用起来功耗和速度都不行啦，所以要加速撒，本文从**算法**和**硬件**两个方面的加速方法作了总结。
  >
  >**算法方面**：network pruning，low-rank approximation，network quantization，teacher-student networks，compact network design
  >
  >**硬件方面**：硬件加速器

* **算法方面的加速**

  * **Network Pruning** 

    ![1556202192083](201904工作记录.assets/1556202192083.png)

    * Fine-gained Pruning
    * Vector-level and Kernel-level Pruning Vector-level
    * Group-level Pruning Group-level
    * Filter-level Pruning Filter-level

    * **low-rank approximation**

        * Two-component Decomposition 

          **SVD**: w\*h----w\*1,1*h

        * Three-component Decomposition

          Typical:w\*h----w\*1,1\*h,1\*1

          Tucker decomposition:w\*h----1\*1,w\*h,1\*1,其中w\*h变成了block diagonal tensor

          BTD:low-rank，group sparse decomposition

        * Four-component Decomposition
          Typical:w\*h----1\*1，w\*1,1\*h,1\*1,和CP-decomposition相似

    * **network quantization**

        * Scalar and Vector Quantization Scalar

          code book--quantization codes

          1. 无损编码：Huffman

          2. low-bit fixed points

          1. Scalar: K-means
          2. vector:PQ(主要用于FC)

        * Fixed-point Quantization

          主要从Weights,Activations下手来对inference阶段加速或者降低功耗，也有对Gradient动手的，为了在training阶段优化。

          作者举了一堆网络的例子，具体看论文吧

    * **teacher-student networks**

      KD----FitNets----[91]

      KD:(knowledge distillation)，用teacher的softmax层的输出，也就是feature maps指导学生

      FitNets:deeper

      \[91\](Paying more attention to attention):用teacher的attention maps去指导学生

    * **compact network design**

      1. Network-In-Network: 运用1*1卷积增大网络能力，保证计算复杂度

      2. 为了减少storage，用global average pooling代替fully  connected layer

      3. Branching：

         >* 在GoogLeNet中被提出
         >
         >* SqueezeNet:用1*1卷积和branching
         >* MobileNet：提出depth-wise convolution，结合1*1卷积得到很好效果
         >* ShuffleNet：更好的降低1*1的复杂度是用multiple groups，引入channel shuffle operation增加各个group之间的信息互换

  * **硬件方面的加速**

  * **未来方向**

    1. Non-fine-tuning or Unsupervised Compression

       确实，如果能不需要fine-tuning就可以达到压缩模型但是不降低精度的方法，那么就会是一种通用的方法，网络应该自己去寻找有没有用的参数，但是目前来看，参数有没有用还是由标签给出的监督，所以要想做到自监督去学习，感觉可以参考cycle-gan的思想。包括最近出来的一个Learning Correspondence from the Cycle-Consistency of Time，我们可以写一个Learning to compress from ……

    2. Scalable (Self-adaptive) Compression

       超参数的选取耗费人力，如果网络能自己学习到这些参数就好了

    3. Network Acceleration for Object Detection

       目前压缩只是在object classification表现比较好，但是在detection或者segmentation或者其他方面效果并不好，可能是因为其他任务需要更多的语义信息。

    4. Hardware-software Co-design

# 目前终极目标

- 7月份一篇期刊论文
  - 想法1：关键点识别应用网络，根据返回的步态视频（color+depth）进行训练，得到目标应用明确的网络，适用于中山医院项目
  - 想法2：模型压缩，根据应用场景，在损失不影响应用效果的精度的情况下，进行模型的压缩
- 11月份一篇会议论文
  - 计算机视觉相关，暂无想法

## 分月计划

### 4月份：

- 完成zte模型压缩大赛，看几篇论文
- 完成深度视频和彩色视频结合方向的调研，找一下数据集，细化想法，评估可行性

### 5月份：

- 搭建论文架构
- 跑实验

### 6月份：

### 7月份：

=======
[TOC]



# 分周计划

## 20190404-20190410

### 周总结

- 步态算法监视程序重构，逻辑线更清楚
- 模型压缩相关知识，并参与比赛
- 出差布点
- 课程报告相关准备

## 20190411-20190417

### 周计划

- 模型压缩
- 协助完成语音收集
- 按照计划出差布点
- 看论文
- 课程报告

### 周总结

- 模型压缩看了一些，但是没有看很多，半篇论文（deep compression），研究了几个代码
- 语音收集完成一个人，主动来找的人
- 做实验室网页：<http://webplus.fudan.edu.cn/_s342/main.psp>
- 做课程报告：英语&计算机体系结构
- 总结：这周较多时间花在了实验室网页制作和课程上，关于deep compression的进度较慢，论文和代码方面花费精力较少。下周应作出相应调整

## 20190418-20190424

### 周计划

- 论文：至少两篇（拿人头保证）
- 调研：完成模型压缩调研报告和三维恢复方向调研报告
- 实验室网页优化





# 目前终极目标

- 7月份一篇期刊论文
  - 想法1：关键点识别应用网络，根据返回的步态视频（color+depth）进行训练，得到目标应用明确的网络，适用于中山医院项目
  - 想法2：模型压缩，根据应用场景，在损失不影响应用效果的精度的情况下，进行模型的压缩
- 11月份一篇会议论文
  - 计算机视觉相关，暂无想法

## 分月计划

### 4月份：

- 完成zte模型压缩大赛，看几篇论文
- 完成深度视频和彩色视频结合方向的调研，找一下数据集，细化想法，评估可行性

### 5月份：

- 搭建论文架构
- 跑实验

### 6月份：

### 7月份：

>>>>>>> 008bb65435b66ba191c15489795fa7a70285ba9e
